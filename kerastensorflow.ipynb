{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>db benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>4.710446</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>22.188299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>db benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>360.458980</td>\n",
       "      <td>35.789338</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>360.275733</td>\n",
       "      <td>35.923972</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>360.091968</td>\n",
       "      <td>35.991542</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>9.034660</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>81.625077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>db benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>db benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>172.140917</td>\n",
       "      <td>18487.448750</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>182.560279</td>\n",
       "      <td>18928.175300</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>193.165753</td>\n",
       "      <td>19153.795810</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>db benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
       "0          1.000000       60.000000            0.000000          1.000000   \n",
       "1          1.000000      354.000000            0.000000          1.000000   \n",
       "2          1.857879      360.458980           35.789338          1.912127   \n",
       "3          1.000000      337.000000            0.000000          1.000000   \n",
       "4          1.680223      172.140917        18487.448750          1.793580   \n",
       "\n",
       "   MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
       "0       60.000000            0.000000          1.000000       60.000000   \n",
       "1      354.000000            0.000000          1.000000      354.000000   \n",
       "2      360.275733           35.923972          1.969807      360.091968   \n",
       "3      337.000000            0.000000          1.000000      337.000000   \n",
       "4      182.560279        18928.175300          1.925828      193.165753   \n",
       "\n",
       "   MI_dir_L1_variance  MI_dir_L0.1_weight    ...      HpHp_L0.1_covariance  \\\n",
       "0            0.000000            1.000000    ...                       0.0   \n",
       "1            0.000000            1.000000    ...                       0.0   \n",
       "2           35.991542            1.996939    ...                       0.0   \n",
       "3            0.000000            1.000000    ...                       0.0   \n",
       "4        19153.795810            1.992323    ...                       0.0   \n",
       "\n",
       "   HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
       "0            0.0           1.000000        60.000000        0.000000   \n",
       "1            0.0           5.319895       344.262695        4.710446   \n",
       "2            0.0           6.318264       347.703087        9.034660   \n",
       "3            0.0           1.000000       337.000000        0.000000   \n",
       "4            0.0           1.000000        60.000000        0.000000   \n",
       "\n",
       "   HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
       "0             60.000000           0.000000                    0.0   \n",
       "1            344.262695          22.188299                    0.0   \n",
       "2            347.703087          81.625077                    0.0   \n",
       "3            337.000000           0.000000                    0.0   \n",
       "4             60.000000           0.000000                    0.0   \n",
       "\n",
       "   HpHp_L0.01_pcc       type  \n",
       "0             0.0  db benign  \n",
       "1             0.0  db benign  \n",
       "2             0.0  db benign  \n",
       "3             0.0  db benign  \n",
       "4             0.0  db benign  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# db_benign refers to the benign dataset of the doorbell. Other variable names follow a similar nomenclature.\n",
    "db_benign = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Doorbell\\\\benign_traffic.csv\", sep = ',')\n",
    "db_benign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tcp = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Doorbell\\\\tcp.csv\", sep = ',')\n",
    "db_combo = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Doorbell\\\\combo.csv\", sep = ',')\n",
    "db_junk = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Doorbell\\\\junk.csv\", sep = ',')\n",
    "db_scan = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Doorbell\\\\scan.csv\", sep = ',')\n",
    "db_udp = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Doorbell\\\\udp.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>db benign</th>\n",
       "      <td>49548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db combo</th>\n",
       "      <td>59718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db junk</th>\n",
       "      <td>29068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db scan</th>\n",
       "      <td>29849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db tcp</th>\n",
       "      <td>92141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db udp</th>\n",
       "      <td>105874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        type\n",
       "type             \n",
       "db benign   49548\n",
       "db combo    59718\n",
       "db junk     29068\n",
       "db scan     29849\n",
       "db tcp      92141\n",
       "db udp     105874"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_merge = db_benign.append([db_tcp, db_combo, db_junk, db_scan, db_udp],ignore_index=True)\n",
    "db_merge.to_csv('C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Doorbell\\\\doorbellmerge.csv',index=False)\n",
    "pd.crosstab(db_merge.type, columns = 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    type\n",
       "type         \n",
       "0       49548\n",
       "1       59718\n",
       "2       29068\n",
       "3       29849\n",
       "4       92141\n",
       "5      105874"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_merge['type'] = db_merge['type'].map({'db benign': 0, 'db combo': 1, 'db junk': 2, 'db scan': 3, 'db tcp': 4, 'db udp': 5})\n",
    "pd.crosstab(db_merge.type, columns = 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_merge['device'] = 'doorbell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>type</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>doorbell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.319895</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>4.710446</td>\n",
       "      <td>344.262695</td>\n",
       "      <td>22.188299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>doorbell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.857879</td>\n",
       "      <td>360.458980</td>\n",
       "      <td>35.789338</td>\n",
       "      <td>1.912127</td>\n",
       "      <td>360.275733</td>\n",
       "      <td>35.923972</td>\n",
       "      <td>1.969807</td>\n",
       "      <td>360.091968</td>\n",
       "      <td>35.991542</td>\n",
       "      <td>1.996939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.318264</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>9.034660</td>\n",
       "      <td>347.703087</td>\n",
       "      <td>81.625077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>doorbell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>337.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>doorbell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680223</td>\n",
       "      <td>172.140917</td>\n",
       "      <td>18487.448750</td>\n",
       "      <td>1.793580</td>\n",
       "      <td>182.560279</td>\n",
       "      <td>18928.175300</td>\n",
       "      <td>1.925828</td>\n",
       "      <td>193.165753</td>\n",
       "      <td>19153.795810</td>\n",
       "      <td>1.992323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>doorbell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
       "0          1.000000       60.000000            0.000000          1.000000   \n",
       "1          1.000000      354.000000            0.000000          1.000000   \n",
       "2          1.857879      360.458980           35.789338          1.912127   \n",
       "3          1.000000      337.000000            0.000000          1.000000   \n",
       "4          1.680223      172.140917        18487.448750          1.793580   \n",
       "\n",
       "   MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
       "0       60.000000            0.000000          1.000000       60.000000   \n",
       "1      354.000000            0.000000          1.000000      354.000000   \n",
       "2      360.275733           35.923972          1.969807      360.091968   \n",
       "3      337.000000            0.000000          1.000000      337.000000   \n",
       "4      182.560279        18928.175300          1.925828      193.165753   \n",
       "\n",
       "   MI_dir_L1_variance  MI_dir_L0.1_weight    ...     HpHp_L0.1_pcc  \\\n",
       "0            0.000000            1.000000    ...               0.0   \n",
       "1            0.000000            1.000000    ...               0.0   \n",
       "2           35.991542            1.996939    ...               0.0   \n",
       "3            0.000000            1.000000    ...               0.0   \n",
       "4        19153.795810            1.992323    ...               0.0   \n",
       "\n",
       "   HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  HpHp_L0.01_magnitude  \\\n",
       "0           1.000000        60.000000        0.000000             60.000000   \n",
       "1           5.319895       344.262695        4.710446            344.262695   \n",
       "2           6.318264       347.703087        9.034660            347.703087   \n",
       "3           1.000000       337.000000        0.000000            337.000000   \n",
       "4           1.000000        60.000000        0.000000             60.000000   \n",
       "\n",
       "   HpHp_L0.01_radius  HpHp_L0.01_covariance  HpHp_L0.01_pcc  type    device  \n",
       "0           0.000000                    0.0             0.0     0  doorbell  \n",
       "1          22.188299                    0.0             0.0     0  doorbell  \n",
       "2          81.625077                    0.0             0.0     0  doorbell  \n",
       "3           0.000000                    0.0             0.0     0  doorbell  \n",
       "4           0.000000                    0.0             0.0     0  doorbell  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to search for singular values\n",
    "\n",
    "def which(self):\n",
    "    try:\n",
    "        self = list(iter(self))\n",
    "    except TypeError as e:\n",
    "        raise Exception(\"\"\"'which' method can only be applied to iterables.\n",
    "        {}\"\"\".format(str(e)))\n",
    "    indices = [i for i, x in enumerate(self) if bool(x) == True]\n",
    "    return(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legitcols=which(db_merge.apply(pd.Series.nunique) != 1) \n",
    "len(legitcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = db_merge.values\n",
    "X = dataset[:,0:115].astype(float)\n",
    "Y = dataset[:,115].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KISHALAY\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:176: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "db_train, db_test, y_train, y_test = sklearn.model_selection.train_test_split(X_scaled,dummy_y, test_size = 0.25)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   label\n",
       "row_0        \n",
       "0       49548\n",
       "1       59718\n",
       "2       29068\n",
       "3       29849\n",
       "4       92141\n",
       "5      105874"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(Y,columns='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definiton \n",
    "# This model has given the best training accuracy (91%) till now. The accuracy improved after Encoding, increasing a hidden layer, and changing the activation function for some layers.\n",
    "# According to DataScience article, Softmax is the best for multiclass classification. Maybe use Softmax for another layer??\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(200, input_dim=115, activation='softmax'))\n",
    "model1.add(Dense(200, activation='relu'))\n",
    "model1.add(Dense(150, activation='relu'))\n",
    "model1.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "274648/274648 [==============================] - 21s 78us/step - loss: 0.1436 - acc: 0.9051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e4c050a128>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the model (using fewer epochs, to save time)\n",
    "# TODO : Increase number of epochs and maybe decrease batch size to see if accuracy improves. Adding another layer is also an option.\n",
    "model1.fit(db_train, y_train, epochs=1, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274648/274648 [==============================] - 7s 27us/step\n",
      "\n",
      "acc: 91.16%\n"
     ]
    }
   ],
   "source": [
    "# model1 evaluation\n",
    "scores = model1.evaluate(db_train, y_train)\n",
    "print(\"\\n%s: %.2f%%\" % (model1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.predict(db_test)\n",
    "#rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predictions)):\n",
    "    a = 0\n",
    "    indexpred = 0\n",
    "    for j in range(6):\n",
    "        if predictions[i][j] > a:\n",
    "            a = predictions[i][j]\n",
    "            indexpred = j\n",
    "            \n",
    "    for k in range(6):\n",
    "        if k==indexpred:\n",
    "            predictions[i][k] = 1\n",
    "        else:\n",
    "            predictions[i][k] = 0\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     5,     11,     17, ..., 549284, 549293, 549299], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_pred = np.where(np.in1d(predictions, [1]))[0]\n",
    "index_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 2, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_pred = index_pred%6\n",
    "index_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, ..., 2, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.where(np.in1d(y_test, [1]))[0]\n",
    "index = index%6\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we generate the confusion matrix of true values against predictions. The rows are the true values and the columns represent the predictions.\n",
    "We next calculate the specificity for each label. We avoid calculating accuracy because ....**TODO**(from DST 2 project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12373,     0,     3,     2,     0,     1],\n",
       "       [    4, 14851,   165,     9,     0,     0],\n",
       "       [    1,   913,  6416,     7,     0,     0],\n",
       "       [   11,     3,    34,  7431,     1,     5],\n",
       "       [   20,     0,     1,     1,     0, 22809],\n",
       "       [   11,     2,     2,     3,     0, 26471]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.crosstab(index_pred-index, columns=\"Residual\")\n",
    "\n",
    "from  sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(index, index_pred)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994063482840939\n",
      "0.9880032932136277\n",
      "0.9975656965076651\n",
      "0.9997382977457919\n",
      "0.9999854479838182\n",
      "0.6493290911606031\n"
     ]
    }
   ],
   "source": [
    "#for i in range(6):\n",
    "def specificity(confusion_matrix,i):\n",
    "    a=np.array(confusion_matrix)\n",
    "    cols = (np.sum(a, axis=0))\n",
    "    rows = (np.sum(a, axis=1))\n",
    "    true_positives = confusion_matrix[i][i]\n",
    "    true_negatives = sum(sum(confusion_matrix)) - rows[i] - cols[i] + confusion_matrix[i][i]\n",
    "    false_positives = cols[i] - true_positives\n",
    "    return true_negatives/(true_negatives+false_positives)\n",
    "    \n",
    "for i in range(6):\n",
    "    print(specificity(matrix,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12379 15029  7337  7485 22831 26489] [12420 15769  6621  7453     1 49286]\n"
     ]
    }
   ],
   "source": [
    "a=np.array(matrix)\n",
    "cols = (np.sum(a, axis=0))\n",
    "rows = (np.sum(a, axis=1))\n",
    "print(rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995153081832135\n",
      "0.98815623128618\n",
      "0.8744718549816001\n",
      "0.9927855711422846\n",
      "0.0\n",
      "0.9993204726490241\n"
     ]
    }
   ],
   "source": [
    "def sensitivity(confusion_matrix,i):\n",
    "    true_positives = confusion_matrix[i][i]\n",
    "    false_negatives = sum(confusion_matrix[i]) - true_positives\n",
    "    return true_positives/(true_positives+false_negatives)\n",
    "    \n",
    "for i in range(6):\n",
    "    print(sensitivity(matrix,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the sensitivity values are quite good, except for the 5th one. If we examine that row of the confusion matrix, we observe that most of the TCP attacks have been misclassified as UDP attacks. This **(MAYBE???)** needs further study. \n",
    "Also, the converse **DOES NOT** occur, i.e, most UDP connections are classified correctly. \n",
    "**NEED TO WRITE SOME MORE ON THIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_benign = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Thermostat\\\\benign_traffic.csv\", sep = ',')\n",
    "ts_tcp = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Thermostat\\\\tcp.csv\", sep = ',')\n",
    "ts_combo = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Thermostat\\\\combo.csv\", sep = ',')\n",
    "ts_junk = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Thermostat\\\\junk.csv\", sep = ',')\n",
    "ts_scan = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Thermostat\\\\scan.csv\", sep = ',')\n",
    "ts_udp = pd.read_csv(\"C:\\\\Users\\\\KISHALAY\\\\Desktop\\\\tensorflow dataset\\\\Thermostat\\\\udp.csv\", sep = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
