2019-03-21 15:06:21.644445: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-03-21 15:06:21.876937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:0b:00.0
totalMemory: 15.89GiB freeMemory: 13.22GiB
2019-03-21 15:06:21.877005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2019-03-21 15:06:22.103001: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-21 15:06:22.103065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2019-03-21 15:06:22.103075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2019-03-21 15:06:22.103362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12808 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:0b:00.0, compute capability: 6.0)

Determine the best batch size using epoch = 50 :

batch : 250
acc: 92.88%

batch : 500
acc: 92.99%

batch : 1000
acc: 92.83%

batch : 1500
acc: 93.03%

batch : 2000
acc: 92.90%

batch : 2500
acc: 93.00%

batch : 3000
acc: 92.98%

the loss list is
[0.10591754990095636, 0.10399074417650372, 0.10706622768323439, 0.10415672333157225, 0.10584870798823885, 0.10570472137263869, 0.10580628072025626]
the accuracy list is
[92.88164594120354, 92.99113795793173, 92.83451734114388, 93.03464000783688, 92.89808961507316, 92.9974306022086, 92.97737693998776]

the result for every 5 epochs:
[[5, 10, 15, 20, 25, 30, 35, 40, 45, 50], 
[0.9293024833909901, 0.9303730610548888, 0.9303685899876974, 0.9305116648390059, 0.9305166327261842, 0.9304951052112883, 0.9304128041238884, 0.9304960988398915, 0.9260453772306126, 0.9305331923425313], 
[0.9290279957421848, 0.930083171843948, 0.9300911205806118, 0.9302500924428216, 0.9302163108663153, 0.9302356855985323, 0.9301517286359473, 0.9302277370267416, 0.9256165576780846, 0.9302441309557046]]

Confusion matrix for classify 6 types of attack
[[72558    11     6     2     8     7]
 [    0 57421    23     0     0     0]
 [    1    54 28696     0     0     0]
 [    1     1     4 27310     0     0]
 [    7     3     0     4    53 70058]
 [    4     1     0    11     8 79237]]
The sensitivity is 
0.9995316288296231
0.9995996100550101
0.9980870230600675
0.9997803485136916
0.0007557932263814617
0.9996972029118987
The specificity is 
0.9999505509762379
0.9997482421910122
0.9998924163292452
0.9999448361796783
0.9999397054611778
0.7265521332563186

Binary classification for tcp and udp:

col_0  Residual
row_0          
0.0       79083
1.0       69965

col_0   Type
row_0       
0      69965
1      79083

The percentage of rejecting H_0 is :
0.02924740874267688

the result for every 5 epoches after combining tcp and udp:
[[5, 10, 15, 20, 25, 30, 35, 40, 45, 50],
 [0.9994519441824836, 0.9995346096151531, 0.9998529508370537, 0.9998185730509579, 0.9987284231174258, 0.9998601046328713, 0.9998271178161465, 0.9997617406012937, 0.9998668609742155, 0.999846393215366], 
 [0.9994682393322581, 0.9995236807650465, 0.999884347912892, 0.9998277141292387, 0.9987546547316062, 0.9998682520915438, 0.9998491753191243, 0.9997675035317718, 0.9998932901748367, 0.9998330794864055]]

The confusion matrix after combining tcp and udp:
[[ 72541      0      0      0      6]
 [    12  57330     31      0      0]
 [    12     36  29059      0      0]
 [     5      2      0  27503      6]
 [    33      0      0      3 148910]]
 
The sensitivity is 
0.9999172949949687
0.9992505185365939
0.9983509121517161
0.999527547608664
0.9997583016663757
The specificity is 
0.9997642065550578
0.9998633663651139
0.9998988191212278
0.999990258886331
0.9999356716681944

Build the model by hiding "scan" from training set:

Epoch 1/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0863 - acc: 0.9567
Epoch 2/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0324 - acc: 0.9872
Epoch 3/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0081 - acc: 0.9975
Epoch 4/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0057 - acc: 0.9982
Epoch 5/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0048 - acc: 0.9986
Epoch 6/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0035 - acc: 0.9989
Epoch 7/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0034 - acc: 0.9990
Epoch 8/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0024 - acc: 0.9992
Epoch 9/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0025 - acc: 0.9992
Epoch 10/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0023 - acc: 0.9992
Epoch 11/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0017 - acc: 0.9995
Epoch 12/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0020 - acc: 0.9993
Epoch 13/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0015 - acc: 0.9995
Epoch 14/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0037 - acc: 0.9991
Epoch 15/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0016 - acc: 0.9995
Epoch 16/50
923853/923853 [==============================] - 3s 4us/step - loss: 0.0013 - acc: 0.9996
Epoch 17/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0024 - acc: 0.9992
Epoch 18/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0012 - acc: 0.9996
Epoch 19/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0019 - acc: 0.9994
Epoch 20/50
923853/923853 [==============================] - 4s 4us/step - loss: 9.2707e-04 - acc: 0.9997
Epoch 21/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0012 - acc: 0.9996
Epoch 22/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0020 - acc: 0.9994
Epoch 23/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0030 - acc: 0.9992
Epoch 24/50
923853/923853 [==============================] - 4s 4us/step - loss: 8.6445e-04 - acc: 0.9997
Epoch 25/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0013 - acc: 0.9996
Epoch 26/50
923853/923853 [==============================] - 4s 5us/step - loss: 9.9256e-04 - acc: 0.9997
Epoch 27/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0027 - acc: 0.9992
Epoch 28/50
923853/923853 [==============================] - 4s 4us/step - loss: 7.6128e-04 - acc: 0.9998
Epoch 29/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0021 - acc: 0.9994
Epoch 30/50
923853/923853 [==============================] - 4s 4us/step - loss: 8.8429e-04 - acc: 0.9997
Epoch 31/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0014 - acc: 0.9996
Epoch 32/50
923853/923853 [==============================] - 4s 4us/step - loss: 7.7377e-04 - acc: 0.9997
Epoch 33/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0034 - acc: 0.9992
Epoch 34/50
923853/923853 [==============================] - 4s 4us/step - loss: 8.7325e-04 - acc: 0.9997
Epoch 35/50
923853/923853 [==============================] - 4s 4us/step - loss: 7.3519e-04 - acc: 0.9998
Epoch 36/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0014 - acc: 0.9996
Epoch 37/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0012 - acc: 0.9996
Epoch 38/50
923853/923853 [==============================] - 4s 4us/step - loss: 9.8204e-04 - acc: 0.9997
Epoch 39/50
923853/923853 [==============================] - 4s 4us/step - loss: 8.1240e-04 - acc: 0.9998
Epoch 40/50
923853/923853 [==============================] - 4s 4us/step - loss: 8.2814e-04 - acc: 0.9998
Epoch 41/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0016 - acc: 0.9996
Epoch 42/50
923853/923853 [==============================] - 4s 5us/step - loss: 8.8925e-04 - acc: 0.9997
Epoch 43/50
923853/923853 [==============================] - 4s 4us/step - loss: 0.0049 - acc: 0.9988
Epoch 44/50
923853/923853 [==============================] - 4s 5us/step - loss: 7.5344e-04 - acc: 0.9998
Epoch 45/50
923853/923853 [==============================] - 4s 5us/step - loss: 0.0012 - acc: 0.9997
Epoch 46/50
923853/923853 [==============================] - 4s 5us/step - loss: 8.0375e-04 - acc: 0.9998
Epoch 47/50
923853/923853 [==============================] - 4s 5us/step - loss: 0.0020 - acc: 0.9995
Epoch 48/50
923853/923853 [==============================] - 4s 5us/step - loss: 0.0016 - acc: 0.9996
Epoch 49/50
923853/923853 [==============================] - 5s 5us/step - loss: 7.4199e-04 - acc: 0.9998
Epoch 50/50
923853/923853 [==============================] - 4s 5us/step - loss: 9.9126e-04 - acc: 0.9997

The confusion matrix of hiding "scan" from training dataset
[[ 72527      0      0      6     14]
 [    14  55575   1783      1      0]
 [     7      7  29088      5      0]
 [  4855   1219    488     39  20915]
 [    28      0      3      1 148914]]
The sensitivity is 
0.9997243166498959
0.968661216948739
0.9993472360600543
0.00141735717400785
0.9997851570367784
The specificity is 
0.9813494991290855
0.995591767463936
0.992577892957158
0.9999577885074341
0.887806028636829

Build the model by hiding "combo" from training set:

Epoch 1/50
834288/834288 [==============================] - 4s 4us/step - loss: 0.0302 - acc: 0.9941
Epoch 2/50
834288/834288 [==============================] - 4s 4us/step - loss: 0.0034 - acc: 0.9996
Epoch 3/50
834288/834288 [==============================] - 4s 4us/step - loss: 0.0017 - acc: 0.9998
Epoch 4/50
834288/834288 [==============================] - 4s 4us/step - loss: 0.0011 - acc: 0.9998
Epoch 5/50
834288/834288 [==============================] - 4s 4us/step - loss: 8.2730e-04 - acc: 0.9999
Epoch 6/50
834288/834288 [==============================] - 3s 4us/step - loss: 7.1466e-04 - acc: 0.9999
Epoch 7/50
834288/834288 [==============================] - 4s 4us/step - loss: 5.6174e-04 - acc: 0.9999
Epoch 8/50
834288/834288 [==============================] - 4s 4us/step - loss: 4.8777e-04 - acc: 0.9999
Epoch 9/50
834288/834288 [==============================] - 4s 4us/step - loss: 4.4427e-04 - acc: 0.9999
Epoch 10/50
834288/834288 [==============================] - 3s 4us/step - loss: 3.8781e-04 - acc: 0.9999
Epoch 11/50
834288/834288 [==============================] - 4s 5us/step - loss: 4.6570e-04 - acc: 0.9999
Epoch 12/50
834288/834288 [==============================] - 4s 4us/step - loss: 3.2985e-04 - acc: 0.9999
Epoch 13/50
834288/834288 [==============================] - 4s 5us/step - loss: 3.4141e-04 - acc: 0.9999
Epoch 14/50
834288/834288 [==============================] - 3s 4us/step - loss: 3.4970e-04 - acc: 0.9999
Epoch 15/50
834288/834288 [==============================] - 3s 4us/step - loss: 3.2311e-04 - acc: 0.9999
Epoch 16/50
834288/834288 [==============================] - 3s 4us/step - loss: 3.6333e-04 - acc: 0.9999
Epoch 17/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.7175e-04 - acc: 0.9999
Epoch 18/50
834288/834288 [==============================] - 4s 4us/step - loss: 2.5571e-04 - acc: 0.9999
Epoch 19/50
834288/834288 [==============================] - 3s 4us/step - loss: 3.7310e-04 - acc: 0.9999
Epoch 20/50
834288/834288 [==============================] - 4s 5us/step - loss: 2.9273e-04 - acc: 0.9999
Epoch 21/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.5600e-04 - acc: 0.9999
Epoch 22/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.4549e-04 - acc: 0.9999
Epoch 23/50
834288/834288 [==============================] - 4s 4us/step - loss: 2.7310e-04 - acc: 0.9999
Epoch 24/50
834288/834288 [==============================] - 4s 4us/step - loss: 3.2539e-04 - acc: 0.9999
Epoch 25/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.5215e-04 - acc: 0.9999
Epoch 26/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.5845e-04 - acc: 0.9999
Epoch 27/50
834288/834288 [==============================] - 3s 4us/step - loss: 3.0441e-04 - acc: 0.9999
Epoch 28/50
834288/834288 [==============================] - 3s 4us/step - loss: 4.8665e-04 - acc: 0.9999
Epoch 29/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.6868e-04 - acc: 0.9999
Epoch 30/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.4384e-04 - acc: 0.9999
Epoch 31/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.6995e-04 - acc: 0.9999
Epoch 32/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.6157e-04 - acc: 0.9999
Epoch 33/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.7283e-04 - acc: 0.9999
Epoch 34/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.8516e-04 - acc: 0.9999
Epoch 35/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.7353e-04 - acc: 0.9999
Epoch 36/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.4479e-04 - acc: 0.9999
Epoch 37/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.3688e-04 - acc: 0.9999
Epoch 38/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.2346e-04 - acc: 0.9999
Epoch 39/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.2144e-04 - acc: 0.9999
Epoch 40/50
834288/834288 [==============================] - 3s 4us/step - loss: 3.1240e-04 - acc: 0.9999
Epoch 41/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.3657e-04 - acc: 0.9999
Epoch 42/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.4144e-04 - acc: 0.9999
Epoch 43/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.7826e-04 - acc: 0.9999
Epoch 44/50
834288/834288 [==============================] - 4s 4us/step - loss: 2.5803e-04 - acc: 0.9999
Epoch 45/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.5497e-04 - acc: 0.9999
Epoch 46/50
834288/834288 [==============================] - 3s 3us/step - loss: 2.5214e-04 - acc: 0.9999
Epoch 47/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.8726e-04 - acc: 0.9999
Epoch 48/50
834288/834288 [==============================] - 4s 4us/step - loss: 2.1385e-04 - acc: 0.9999
Epoch 49/50
834288/834288 [==============================] - 3s 4us/step - loss: 2.4908e-04 - acc: 0.9999
Epoch 50/50
834288/834288 [==============================] - 4s 4us/step - loss: 2.5030e-04 - acc: 0.9999

The confusion matrix of hiding "combo" from training dataset
[[ 72534      0      0      8      5]
 [     7      0  57364      2      0]
 [     4      0  29097      6      0]
 [     1      0      0  27515      0]
 [    15      0      0      7 148924]]
The sensitivity is 
0.9998208058224324
0.0
0.9996564400316075
0.9999636575083588
0.9998522954627852
The specificity is 
0.9998973157578478
1.0
0.8127696796809212
0.9999253181285372
0.9999731965284143

Build the model for detecting different devices:
Epoch 1/50
1006466/1006466 [==============================] - 5s 5us/step - loss: 0.4149 - acc: 0.8014
Epoch 2/50
1006466/1006466 [==============================] - 5s 5us/step - loss: 0.4049 - acc: 0.8036
Epoch 3/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4036 - acc: 0.8038
Epoch 4/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4031 - acc: 0.8039
Epoch 5/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4026 - acc: 0.8039
Epoch 6/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4024 - acc: 0.8040
Epoch 7/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4020 - acc: 0.8040
Epoch 8/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4016 - acc: 0.8041
Epoch 9/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4014 - acc: 0.8041
Epoch 10/50
1006466/1006466 [==============================] - 5s 5us/step - loss: 0.4013 - acc: 0.8041
Epoch 11/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4011 - acc: 0.8042
Epoch 12/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4011 - acc: 0.8041
Epoch 13/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4009 - acc: 0.8042
Epoch 14/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4008 - acc: 0.8042
Epoch 15/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4007 - acc: 0.8042
Epoch 16/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4007 - acc: 0.8042
Epoch 17/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4007 - acc: 0.8042
Epoch 18/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4008 - acc: 0.8042
Epoch 19/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4007 - acc: 0.8042
Epoch 20/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4006 - acc: 0.8042
Epoch 21/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4006 - acc: 0.8042
Epoch 22/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4006 - acc: 0.8042
Epoch 23/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4004 - acc: 0.8043
Epoch 24/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4005 - acc: 0.8043
Epoch 25/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4004 - acc: 0.8042
Epoch 26/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4004 - acc: 0.8042
Epoch 27/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4004 - acc: 0.8042
Epoch 28/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4003 - acc: 0.8043
Epoch 29/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4007 - acc: 0.8041
Epoch 30/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4003 - acc: 0.8043
Epoch 31/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4002 - acc: 0.8043
Epoch 32/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4002 - acc: 0.8043
Epoch 33/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4003 - acc: 0.8042
Epoch 34/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4002 - acc: 0.8043
Epoch 35/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4002 - acc: 0.8043
Epoch 36/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4001 - acc: 0.8043
Epoch 37/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4002 - acc: 0.8043
Epoch 38/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4001 - acc: 0.8043
Epoch 39/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4000 - acc: 0.8043
Epoch 40/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4001 - acc: 0.8043
Epoch 41/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4002 - acc: 0.8042
Epoch 42/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4002 - acc: 0.8043
Epoch 43/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4000 - acc: 0.8043
Epoch 44/50
1006466/1006466 [==============================] - 5s 4us/step - loss: 0.4001 - acc: 0.8043
Epoch 45/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4001 - acc: 0.8042
Epoch 46/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4000 - acc: 0.8043
Epoch 47/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.3999 - acc: 0.8043
Epoch 48/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4000 - acc: 0.8043
Epoch 49/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4001 - acc: 0.8043
Epoch 50/50
1006466/1006466 [==============================] - 4s 4us/step - loss: 0.4004 - acc: 0.8042


confusion matrix of classifying 4 types of devices:
[[15979  1403 59797 14517]
 [ 2580 45469 59582 14195]
 [ 2763   566 63047 14489]
 [ 2276  1298  9689 27839]]
The sensitivity is 
0.17426060024428547
0.3732290315696157
0.779657453780993
0.6773149725074206
The specificity is 
0.9687480772622675
0.9847095659987924
0.4931035566168154
0.8532509927408479

Build the model by hiding "doorbell" from training set:

Epoch 1/50
731964/731964 [==============================] - 3s 5us/step - loss: 0.4247 - acc: 0.7448
Epoch 2/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4122 - acc: 0.7484
Epoch 3/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4108 - acc: 0.7481
Epoch 4/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4099 - acc: 0.7486
Epoch 5/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4092 - acc: 0.7489
Epoch 6/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4084 - acc: 0.7493
Epoch 7/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4083 - acc: 0.7495
Epoch 8/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4078 - acc: 0.7495
Epoch 9/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4073 - acc: 0.7495
Epoch 10/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4070 - acc: 0.7495
Epoch 11/50
731964/731964 [==============================] - 3s 5us/step - loss: 0.4066 - acc: 0.7502
Epoch 12/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4063 - acc: 0.7502
Epoch 13/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4060 - acc: 0.7502
Epoch 14/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4059 - acc: 0.7500
Epoch 15/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4059 - acc: 0.7498
Epoch 16/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4056 - acc: 0.7498
Epoch 17/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4056 - acc: 0.7499
Epoch 18/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4055 - acc: 0.7501
Epoch 19/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4057 - acc: 0.7498
Epoch 20/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4056 - acc: 0.7498
Epoch 21/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4053 - acc: 0.7507
Epoch 22/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4054 - acc: 0.7500
Epoch 23/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4053 - acc: 0.7500
Epoch 24/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4056 - acc: 0.7497
Epoch 25/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4049 - acc: 0.7504
Epoch 26/50
731964/731964 [==============================] - 3s 5us/step - loss: 0.4053 - acc: 0.7502
Epoch 27/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4053 - acc: 0.7500
Epoch 28/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4050 - acc: 0.7501
Epoch 29/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4049 - acc: 0.7504
Epoch 30/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4050 - acc: 0.7498
Epoch 31/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4049 - acc: 0.7501
Epoch 32/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4051 - acc: 0.7505
Epoch 33/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4048 - acc: 0.7500
Epoch 34/50
731964/731964 [==============================] - 4s 5us/step - loss: 0.4049 - acc: 0.7502
Epoch 35/50
731964/731964 [==============================] - 3s 5us/step - loss: 0.4047 - acc: 0.7502
Epoch 36/50
731964/731964 [==============================] - 4s 5us/step - loss: 0.4046 - acc: 0.7504
Epoch 37/50
731964/731964 [==============================] - 3s 5us/step - loss: 0.4050 - acc: 0.7499
Epoch 38/50
731964/731964 [==============================] - 3s 5us/step - loss: 0.4047 - acc: 0.7500
Epoch 39/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4045 - acc: 0.7502
Epoch 40/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4050 - acc: 0.7502
Epoch 41/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4048 - acc: 0.7502
Epoch 42/50
731964/731964 [==============================] - 3s 5us/step - loss: 0.4047 - acc: 0.7502
Epoch 43/50
731964/731964 [==============================] - 3s 5us/step - loss: 0.4047 - acc: 0.7501
Epoch 44/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4046 - acc: 0.7504
Epoch 45/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4044 - acc: 0.7504
Epoch 46/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4046 - acc: 0.7501
Epoch 47/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4046 - acc: 0.7501
Epoch 48/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4046 - acc: 0.7504
Epoch 49/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4048 - acc: 0.7501
Epoch 50/50
731964/731964 [==============================] - 3s 4us/step - loss: 0.4057 - acc: 0.7498
/mnt/storage/software/languages/anaconda/Anaconda3.5-4.2.0-tflow-1.7/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/mnt/storage/software/languages/anaconda/Anaconda3.5-4.2.0-tflow-1.7/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/mnt/storage/software/languages/anaconda/Anaconda3.5-4.2.0-tflow-1.7/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/mnt/storage/software/languages/anaconda/Anaconda3.5-4.2.0-tflow-1.7/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/mnt/storage/software/languages/anaconda/Anaconda3.5-4.2.0-tflow-1.7/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
/mnt/storage/software/languages/anaconda/Anaconda3.5-4.2.0-tflow-1.7/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/mnt/storage/software/languages/anaconda/Anaconda3.5-4.2.0-tflow-1.7/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
assignment4.py:140: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  tcp_udp['Type'] = tcp_udp['Type'].map({'tcp':0, 'udp':1})
  
confusion matrix of hiding "doorbell" from training set:  
[[27307  4373 59115   901]
 [27849 44241 49650    86]
 [27232    33 53366   234]
 [26721   507    11 13863]]
The sensitivity is 
0.29779924969464316
0.3631490814768604
0.6599394051814753
0.3372828572818841
The specificity is 
0.6644612437600751
0.9770058456541376
0.5727975367600855
0.9958523983735695
Exception ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x2b5a7313d390>>
Traceback (most recent call last):
  File "/mnt/storage/software/languages/anaconda/Anaconda3.5-4.2.0-tflow-1.7/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 707, in __del__
TypeError: 'NoneType' object is not callable
