{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1><center>DATA SCIENCE TOOLBOX (COURSEWORK 4)</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2><center>KISHALAY BANERJEE, SHANGLIN ZOU, KATARZYNA STANIEWICZ</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>DEEP LEARNING (USING NEURAL NETWORKS)</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we are supposed to implement Deep Learning in the context of cybersecurity. Keeping this objective in mind, we have attempted to write a Neural Networks model, to run on suitably chosen data set. A detailed description of the data set and the model is provided in the report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 1, we load some useful Python libraries, and set a random seed for our computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seeml\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 1\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import stats\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 2, we load the data in csv format. We also convert the data from a dataframe to an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 2\n",
    "\n",
    "df = pd.read_csv('C:/Users/seeml/Desktop/DATA.csv', error_bad_lines = False)\n",
    "dataset = df.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 3, we extract the numeric columns from the data and standardise them. This is done because data standardisation is somewhat of a pre-requisite for neural networks, and is highly recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 3\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df.iloc[:,0:115])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 4, we extract the column containing attack labels from the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 4\n",
    "\n",
    "Y = dataset[:,115]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 5, we perform One Hot Encoding on the labels, since they fall under categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 5\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 6, we are splitting the data into Training and Test data sets. We are keeping 25% of the data as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 6\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X_scaled,dummy_y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 7, we are running a loop to check which batch size gives the best values for accuracy. All of this calculated for a constant number of epochs (=50).\n",
    "A plot of the batch sizes against accuracy is provided in the main report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch : 250\n",
      "Epoch 1/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1242 - acc: 0.9203\n",
      "Epoch 2/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1071 - acc: 0.9285\n",
      "Epoch 3/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1058 - acc: 0.9292\n",
      "Epoch 4/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1051 - acc: 0.9295\n",
      "Epoch 5/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1050 - acc: 0.9296\n",
      "Epoch 6/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1049 - acc: 0.9296\n",
      "Epoch 7/50\n",
      "1006466/1006466 [==============================] - 16s 15us/step - loss: 0.1044 - acc: 0.9298\n",
      "Epoch 8/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1044 - acc: 0.9298\n",
      "Epoch 9/50\n",
      "1006466/1006466 [==============================] - 17s 16us/step - loss: 0.1044 - acc: 0.9298\n",
      "Epoch 10/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1044 - acc: 0.9298\n",
      "Epoch 11/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1041 - acc: 0.9300\n",
      "Epoch 12/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1042 - acc: 0.9299\n",
      "Epoch 13/50\n",
      "1006466/1006466 [==============================] - 17s 17us/step - loss: 0.1041 - acc: 0.9299\n",
      "Epoch 14/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1041 - acc: 0.9300\n",
      "Epoch 15/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1039 - acc: 0.9301\n",
      "Epoch 16/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1040 - acc: 0.9301\n",
      "Epoch 17/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1040 - acc: 0.9300\n",
      "Epoch 18/50\n",
      "1006466/1006466 [==============================] - 17s 17us/step - loss: 0.1040 - acc: 0.9301\n",
      "Epoch 19/50\n",
      "1006466/1006466 [==============================] - 17s 16us/step - loss: 0.1039 - acc: 0.9302\n",
      "Epoch 20/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1038 - acc: 0.9301\n",
      "Epoch 21/50\n",
      "1006466/1006466 [==============================] - 17s 17us/step - loss: 0.1041 - acc: 0.9300\n",
      "Epoch 22/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1041 - acc: 0.9300\n",
      "Epoch 23/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 24/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1038 - acc: 0.9302\n",
      "Epoch 25/50\n",
      "1006466/1006466 [==============================] - 15s 14us/step - loss: 0.1052 - acc: 0.9301\n",
      "Epoch 26/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 27/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 28/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1094 - acc: 0.9288\n",
      "Epoch 29/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1043 - acc: 0.9301\n",
      "Epoch 30/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1039 - acc: 0.9302\n",
      "Epoch 31/50\n",
      "1006466/1006466 [==============================] - 17s 17us/step - loss: 0.1039 - acc: 0.9301\n",
      "Epoch 32/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1039 - acc: 0.9302\n",
      "Epoch 33/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1038 - acc: 0.9302\n",
      "Epoch 34/50\n",
      "1006466/1006466 [==============================] - 17s 17us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 35/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 36/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 37/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 38/50\n",
      "1006466/1006466 [==============================] - 17s 17us/step - loss: 0.1041 - acc: 0.9301\n",
      "Epoch 39/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1038 - acc: 0.9302\n",
      "Epoch 40/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1039 - acc: 0.9302\n",
      "Epoch 41/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1040 - acc: 0.9301\n",
      "Epoch 42/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1040 - acc: 0.9302\n",
      "Epoch 43/50\n",
      "1006466/1006466 [==============================] - 17s 16us/step - loss: 0.1039 - acc: 0.9302\n",
      "Epoch 44/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 45/50\n",
      "1006466/1006466 [==============================] - 16s 15us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 46/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 47/50\n",
      "1006466/1006466 [==============================] - 15s 15us/step - loss: 0.1041 - acc: 0.9302\n",
      "Epoch 48/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 49/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1038 - acc: 0.9302\n",
      "Epoch 50/50\n",
      "1006466/1006466 [==============================] - 16s 16us/step - loss: 0.1037 - acc: 0.9302\n",
      "1006466/1006466 [==============================] - 19s 19us/step\n",
      "\n",
      "acc: 93.02%\n",
      "batch : 500\n",
      "Epoch 1/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1289 - acc: 0.9203\n",
      "Epoch 2/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1072 - acc: 0.9289\n",
      "Epoch 3/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1058 - acc: 0.9293\n",
      "Epoch 4/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1051 - acc: 0.9296\n",
      "Epoch 5/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1046 - acc: 0.9298\n",
      "Epoch 6/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1043 - acc: 0.9299\n",
      "Epoch 7/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1044 - acc: 0.9299\n",
      "Epoch 8/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1042 - acc: 0.9300\n",
      "Epoch 9/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1040 - acc: 0.9300\n",
      "Epoch 10/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1038 - acc: 0.9301\n",
      "Epoch 11/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1038 - acc: 0.9301\n",
      "Epoch 12/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1038 - acc: 0.9301\n",
      "Epoch 13/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1037 - acc: 0.9301\n",
      "Epoch 14/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 15/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 16/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1037 - acc: 0.9301\n",
      "Epoch 17/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1037 - acc: 0.9301\n",
      "Epoch 18/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 19/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 20/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 21/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 22/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 23/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 24/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 25/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 26/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1038 - acc: 0.9302\n",
      "Epoch 28/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9302\n",
      "Epoch 29/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9303\n",
      "Epoch 30/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 31/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 32/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 33/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9301\n",
      "Epoch 34/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9303\n",
      "Epoch 35/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 36/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1037 - acc: 0.9303\n",
      "Epoch 37/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 38/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9302\n",
      "Epoch 39/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9303\n",
      "Epoch 40/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 41/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 42/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 43/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 44/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 45/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9302\n",
      "Epoch 46/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 47/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 48/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 49/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 50/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "1006466/1006466 [==============================] - 20s 19us/step\n",
      "\n",
      "acc: 93.04%\n",
      "batch : 1000\n",
      "Epoch 1/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1491 - acc: 0.9107\n",
      "Epoch 2/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1102 - acc: 0.9285\n",
      "Epoch 3/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1067 - acc: 0.9291\n",
      "Epoch 4/50\n",
      "1006466/1006466 [==============================] - 12s 11us/step - loss: 0.1051 - acc: 0.9297\n",
      "Epoch 5/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1064 - acc: 0.9294\n",
      "Epoch 6/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1047 - acc: 0.9298\n",
      "Epoch 7/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1043 - acc: 0.9299\n",
      "Epoch 8/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1043 - acc: 0.9299\n",
      "Epoch 9/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1037 - acc: 0.9301\n",
      "Epoch 10/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1039 - acc: 0.9301\n",
      "Epoch 11/50\n",
      "1006466/1006466 [==============================] - 12s 11us/step - loss: 0.1038 - acc: 0.9301\n",
      "Epoch 12/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9301\n",
      "Epoch 13/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1040 - acc: 0.9300\n",
      "Epoch 14/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1034 - acc: 0.9302\n",
      "Epoch 15/50\n",
      "1006466/1006466 [==============================] - 12s 11us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 16/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 17/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1034 - acc: 0.9302\n",
      "Epoch 18/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1034 - acc: 0.9302\n",
      "Epoch 19/50\n",
      "1006466/1006466 [==============================] - 12s 11us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 20/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1033 - acc: 0.9302\n",
      "Epoch 21/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1033 - acc: 0.9302\n",
      "Epoch 22/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 23/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 24/50\n",
      "1006466/1006466 [==============================] - 12s 11us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 25/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 26/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 27/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 28/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1032 - acc: 0.9304\n",
      "Epoch 29/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1039 - acc: 0.9302\n",
      "Epoch 30/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 31/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 32/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 33/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1027 - acc: 0.9304\n",
      "Epoch 34/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 35/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 36/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1040 - acc: 0.9302\n",
      "Epoch 37/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 38/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 39/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 40/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 41/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 42/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 43/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 44/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1028 - acc: 0.9304\n",
      "Epoch 45/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1040 - acc: 0.9303\n",
      "Epoch 46/50\n",
      "1006466/1006466 [==============================] - 12s 11us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 47/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 48/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 49/50\n",
      "1006466/1006466 [==============================] - 12s 11us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 50/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.1035 - acc: 0.9303\n",
      "1006466/1006466 [==============================] - 21s 21us/step\n",
      "\n",
      "acc: 93.05%\n",
      "batch : 1500\n",
      "Epoch 1/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1579 - acc: 0.9070\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1120 - acc: 0.9282\n",
      "Epoch 3/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1066 - acc: 0.9293\n",
      "Epoch 4/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1054 - acc: 0.9296\n",
      "Epoch 5/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1048 - acc: 0.9298\n",
      "Epoch 6/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1044 - acc: 0.9299\n",
      "Epoch 7/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1045 - acc: 0.9299\n",
      "Epoch 8/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1039 - acc: 0.9301\n",
      "Epoch 9/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 10/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9301\n",
      "Epoch 11/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1037 - acc: 0.9301\n",
      "Epoch 12/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1038 - acc: 0.9301\n",
      "Epoch 13/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 14/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 15/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1044 - acc: 0.9300\n",
      "Epoch 16/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 17/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 18/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 19/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1040 - acc: 0.9302\n",
      "Epoch 20/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 21/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1033 - acc: 0.9302\n",
      "Epoch 22/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 23/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 24/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 25/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9303\n",
      "Epoch 26/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 27/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 28/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9303\n",
      "Epoch 29/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 30/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9303\n",
      "Epoch 31/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 32/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 33/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 34/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 35/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 36/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 37/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 38/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 39/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 40/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 41/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 42/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9304\n",
      "Epoch 43/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 44/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 45/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305 0s - loss: 0.1026 - acc:\n",
      "Epoch 46/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 47/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 48/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1026 - acc: 0.9305 1s - loss: 0\n",
      "Epoch 49/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1045 - acc: 0.9302\n",
      "Epoch 50/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9304\n",
      "1006466/1006466 [==============================] - 21s 20us/step\n",
      "\n",
      "acc: 93.05%\n",
      "batch : 2000\n",
      "Epoch 1/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1836 - acc: 0.8963\n",
      "Epoch 2/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1433 - acc: 0.9087\n",
      "Epoch 3/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1251 - acc: 0.9208\n",
      "Epoch 4/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1093 - acc: 0.9286\n",
      "Epoch 5/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1066 - acc: 0.9294\n",
      "Epoch 6/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1056 - acc: 0.9297\n",
      "Epoch 7/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1051 - acc: 0.9298\n",
      "Epoch 8/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1070 - acc: 0.9294\n",
      "Epoch 9/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1042 - acc: 0.9302\n",
      "Epoch 10/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1038 - acc: 0.9302\n",
      "Epoch 11/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1038 - acc: 0.9302\n",
      "Epoch 12/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 13/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 14/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1033 - acc: 0.9303 0s - loss: 0.1033\n",
      "Epoch 15/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1057 - acc: 0.9299\n",
      "Epoch 16/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 17/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 18/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 19/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 20/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9301\n",
      "Epoch 21/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1057 - acc: 0.9298\n",
      "Epoch 22/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1029 - acc: 0.9305\n",
      "Epoch 23/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 24/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 25/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 26/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 27/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1028 - acc: 0.9304\n",
      "Epoch 29/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 30/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 31/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 32/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 33/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9304\n",
      "Epoch 34/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1043 - acc: 0.9301\n",
      "Epoch 35/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 36/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 37/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 38/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 39/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1042 - acc: 0.9302\n",
      "Epoch 40/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 41/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 42/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 43/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 44/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 45/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 46/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 47/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 48/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1037 - acc: 0.9302\n",
      "Epoch 49/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9304\n",
      "Epoch 50/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "1006466/1006466 [==============================] - 21s 21us/step\n",
      "\n",
      "acc: 93.05%\n",
      "batch : 3000\n",
      "Epoch 1/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1837 - acc: 0.8969\n",
      "Epoch 2/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1419 - acc: 0.9136\n",
      "Epoch 3/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1220 - acc: 0.9263\n",
      "Epoch 4/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1123 - acc: 0.9290\n",
      "Epoch 5/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1089 - acc: 0.9296\n",
      "Epoch 6/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1076 - acc: 0.9295\n",
      "Epoch 7/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1061 - acc: 0.9299\n",
      "Epoch 8/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1054 - acc: 0.9299\n",
      "Epoch 9/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1048 - acc: 0.9301\n",
      "Epoch 10/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1044 - acc: 0.9302\n",
      "Epoch 11/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1042 - acc: 0.9301\n",
      "Epoch 12/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1040 - acc: 0.9301\n",
      "Epoch 13/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9303\n",
      "Epoch 14/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 15/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.1051 - acc: 0.9299\n",
      "Epoch 16/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1032 - acc: 0.9304\n",
      "Epoch 17/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1035 - acc: 0.9303\n",
      "Epoch 18/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 19/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.1033 - acc: 0.9304\n",
      "Epoch 20/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 21/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.1040 - acc: 0.9302\n",
      "Epoch 22/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 23/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 24/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 25/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 26/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305 1s - loss: 0.102\n",
      "Epoch 27/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 28/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 29/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 30/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 31/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 32/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1039 - acc: 0.9302\n",
      "Epoch 33/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 34/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 35/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 36/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9303\n",
      "Epoch 37/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 38/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 39/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 40/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1051 - acc: 0.9299\n",
      "Epoch 41/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9305\n",
      "Epoch 42/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 43/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 44/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 45/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 46/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 47/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9304\n",
      "Epoch 48/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 49/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 50/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "1006466/1006466 [==============================] - 22s 21us/step\n",
      "\n",
      "acc: 93.05%\n",
      "batch : 4000\n",
      "Epoch 1/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1904 - acc: 0.8948\n",
      "Epoch 2/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.1478 - acc: 0.9071\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1368 - acc: 0.9167\n",
      "Epoch 4/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1184 - acc: 0.9275\n",
      "Epoch 5/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1105 - acc: 0.9288\n",
      "Epoch 6/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1077 - acc: 0.9295\n",
      "Epoch 7/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1064 - acc: 0.9298\n",
      "Epoch 8/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1058 - acc: 0.9298\n",
      "Epoch 9/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1055 - acc: 0.9298\n",
      "Epoch 10/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1047 - acc: 0.9301\n",
      "Epoch 11/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1044 - acc: 0.9301 0s - loss: 0.1045 - acc: 0\n",
      "Epoch 12/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1042 - acc: 0.9302\n",
      "Epoch 13/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1042 - acc: 0.9301\n",
      "Epoch 14/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1040 - acc: 0.9301\n",
      "Epoch 15/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1035 - acc: 0.9303\n",
      "Epoch 16/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1039 - acc: 0.9300\n",
      "Epoch 17/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1033 - acc: 0.9304\n",
      "Epoch 18/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 19/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1099 - acc: 0.9287\n",
      "Epoch 20/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1034 - acc: 0.9304\n",
      "Epoch 21/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1039 - acc: 0.9301\n",
      "Epoch 22/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1032 - acc: 0.9304\n",
      "Epoch 23/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 24/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 25/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 26/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1039 - acc: 0.9301\n",
      "Epoch 27/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 28/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 29/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1034 - acc: 0.9302\n",
      "Epoch 30/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1028 - acc: 0.9304\n",
      "Epoch 31/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1038 - acc: 0.9302\n",
      "Epoch 32/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 33/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 34/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1039 - acc: 0.9301\n",
      "Epoch 35/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 36/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 37/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1039 - acc: 0.9302\n",
      "Epoch 38/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 39/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 40/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 41/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1039 - acc: 0.9301\n",
      "Epoch 42/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 43/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 44/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 45/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 46/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1046 - acc: 0.9298\n",
      "Epoch 47/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1029 - acc: 0.9305\n",
      "Epoch 48/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1027 - acc: 0.9305 0s - loss: 0.1027 - \n",
      "Epoch 49/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 50/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1026 - acc: 0.9305\n",
      "1006466/1006466 [==============================] - 23s 23us/step\n",
      "\n",
      "acc: 93.05%\n",
      "[93.01847790925937, 93.03901180464857, 93.05244163245915, 93.05134869538485, 93.04747375589344, 93.05187860751973, 93.05111686425053]\n",
      "[0.10372396377420207, 0.10300771891882742, 0.10261201588636779, 0.10264106580194694, 0.10268245448215298, 0.10255323699945745, 0.10257453471968515]\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 7\n",
    "\n",
    "batch_size = [250,500,1000,1500,2000,3000,4000]\n",
    "acc = list()\n",
    "loss = list()\n",
    "for i in batch_size:\n",
    "    print(\"batch : \" + str(i))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(250, input_dim=115, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(25, activation='sigmoid'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=i)\n",
    "    scaledtorscores = model.evaluate(X_train, y_train)\n",
    "    loss.append(scaledtorscores[0])\n",
    "    acc.append(scaledtorscores[1]*100)\n",
    "    print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scaledtorscores[1]*100))\n",
    "print(acc)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 8, we define our model. We decided on 4 layers with their respective activation functions after some trial and error with various combinations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 8\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(250, input_dim=115, activation='relu'))\n",
    "model1.add(Dense(250, activation='relu'))\n",
    "model1.add(Dense(25, activation='sigmoid'))\n",
    "model1.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 9, we compile the model we have just written. We have chosen the loss and optimiser after some deliberation, which have been detailed in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 9\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 10, we are fitting our model on the training data, and obtaining values for the accuracy obtained at each epoch.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.1621 - acc: 0.9033\n",
      "Epoch 2/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1206 - acc: 0.9261\n",
      "Epoch 3/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1088 - acc: 0.9291\n",
      "Epoch 4/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1062 - acc: 0.9295\n",
      "Epoch 5/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1052 - acc: 0.9298\n",
      "Epoch 6/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1046 - acc: 0.9300\n",
      "Epoch 7/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1043 - acc: 0.9300\n",
      "Epoch 8/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1039 - acc: 0.9301\n",
      "Epoch 9/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 10/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9302\n",
      "Epoch 11/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1046 - acc: 0.9299\n",
      "Epoch 12/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 13/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9302\n",
      "Epoch 14/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9303\n",
      "Epoch 15/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1036 - acc: 0.9302\n",
      "Epoch 16/50\n",
      "1006466/1006466 [==============================] - 14s 13us/step - loss: 0.1032 - acc: 0.9304\n",
      "Epoch 17/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 18/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1041 - acc: 0.9301\n",
      "Epoch 19/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1032 - acc: 0.9303 3s - loss: 0.103 - ETA: 2s - loss: 0.1031 - acc:  - E\n",
      "Epoch 20/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 21/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 22/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9303\n",
      "Epoch 23/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1043 - acc: 0.9300\n",
      "Epoch 24/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 25/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 26/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1030 - acc: 0.9304\n",
      "Epoch 27/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1031 - acc: 0.9304\n",
      "Epoch 28/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 29/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 30/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9304\n",
      "Epoch 31/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9304\n",
      "Epoch 32/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1035 - acc: 0.9303\n",
      "Epoch 33/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1032 - acc: 0.9304\n",
      "Epoch 34/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1050 - acc: 0.9300\n",
      "Epoch 35/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9304\n",
      "Epoch 36/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1026 - acc: 0.9305\n",
      "Epoch 37/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1029 - acc: 0.9304\n",
      "Epoch 38/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1028 - acc: 0.9305\n",
      "Epoch 39/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1038 - acc: 0.9302\n",
      "Epoch 40/50\n",
      "1006466/1006466 [==============================] - 14s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 41/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1033 - acc: 0.9303\n",
      "Epoch 42/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 43/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1032 - acc: 0.9304\n",
      "Epoch 44/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 45/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1040 - acc: 0.9302\n",
      "Epoch 46/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1052 - acc: 0.9301\n",
      "Epoch 47/50\n",
      "1006466/1006466 [==============================] - 15s 14us/step - loss: 0.1028 - acc: 0.9305 0s - loss: 0.1028 - acc: \n",
      "Epoch 48/50\n",
      "1006466/1006466 [==============================] - 14s 13us/step - loss: 0.1034 - acc: 0.9303\n",
      "Epoch 49/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.1027 - acc: 0.9305\n",
      "Epoch 50/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.1032 - acc: 0.9303\n",
      "1006466/1006466 [==============================] - 25s 24us/step\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 10\n",
    "\n",
    "model1.fit(X_train, y_train, epochs=50, batch_size=1500)\n",
    "scores = model1.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 11, our model is generating predictions of the test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.74681709e-08, 1.15118991e-03, 9.98845816e-01, 2.74359508e-07,\n",
       "        1.21515683e-07, 2.65752146e-06],\n",
       "       [1.02549791e-06, 9.99883175e-01, 1.12591115e-04, 1.56158208e-07,\n",
       "        3.09858308e-07, 2.63331344e-06],\n",
       "       [2.02766514e-05, 1.01627065e-05, 2.57692341e-06, 8.71282793e-07,\n",
       "        4.73164260e-01, 5.26801825e-01],\n",
       "       ...,\n",
       "       [3.04167513e-09, 9.99986172e-01, 1.37643910e-05, 1.86343563e-09,\n",
       "        3.77032272e-09, 8.34320844e-08],\n",
       "       [5.64243186e-09, 9.99969244e-01, 3.05806279e-05, 4.01430755e-09,\n",
       "        6.80386547e-09, 1.40664781e-07],\n",
       "       [7.44478168e-09, 2.78336782e-04, 9.99720752e-01, 9.67677352e-08,\n",
       "        3.03350056e-08, 6.94766356e-07]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 11\n",
    "\n",
    "predictions = model1.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Code Chunk 12. \n",
    "Unlike the test labels, our predicted labels aren't in the form of 0's or 1's. Rather, they give the values of the probability of a particular observation belonging to a particular class. For comparison, we need to convert them to binary. To do this, we run a nested loop system. In the outer loop, we are storing the index (position) of the highest numeric value in that row. In the inner loop, we are converting that value to 1, and converting the rest of the values of that row to 0. This is logical because, the prediction with the highest numeric value is expected to be the most probable class of that particular observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 12\n",
    "\n",
    "prediction = predictions\n",
    "for i in range(len(prediction)):\n",
    "    a = 0\n",
    "    indexpred = 0\n",
    "    for j in range(6):\n",
    "        if prediction[i][j] > a:\n",
    "            a = prediction[i][j]\n",
    "            indexpred = j\n",
    "            \n",
    "    for k in range(6):\n",
    "        if k==indexpred:\n",
    "            prediction[i][k] = 1\n",
    "        else:\n",
    "            prediction[i][k] = 0\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 13, we are extracting the index values of each of the predictions (after binarising) made in the previous step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      2,       7,      17, ..., 2012917, 2012923, 2012930],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 13\n",
    "\n",
    "index_pred = np.where(np.in1d(prediction, [1]))[0]\n",
    "index_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 14, we are taking the mod of the index values with respect to 6, so that we get values between 0 and 5. This is because we are dealing with 6 different types of traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 5, ..., 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 14\n",
    "\n",
    "index_pred = index_pred%6\n",
    "index_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 15, we are similarly extracting the indices of the actual test data set values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 15\n",
    "\n",
    "index =  np.where(np.in1d(y_test, [1]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 16, we are again taking the mod wrt 6, to get values between 0 and 5, for the actual test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 4, ..., 1, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 16\n",
    "\n",
    "index = index%6\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 17, we are generating the confusion matrix of the actual and predicted labels of the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72582,     0,     0,     3,     0,     7],\n",
       "       [   18, 57401,    24,     1,     0,     0],\n",
       "       [   13,    27, 28710,     1,     0,     0],\n",
       "       [    7,     0,     0, 27309,     0,     0],\n",
       "       [   27,     0,     0,     1,    38, 70059],\n",
       "       [    9,     0,     0,     1,     7, 79244]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 17\n",
    "\n",
    "matrix = confusion_matrix(index,index_pred)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 18, we are generating a heatmap of the confusion matrix. We have analysed the heatmap in our report.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 18\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "ax = sn.heatmap(matrix, annot=True,fmt=\"d\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 19, we calculate the sensitivity of each class of traffic in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity is \n",
      "0.9998622437734186\n",
      "0.9992514448854537\n",
      "0.9985739626447776\n",
      "0.9997437399326402\n",
      "0.0005418894830659536\n",
      "0.9997855187292616\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 19\n",
    "\n",
    "def sensitivity(confusion_matrix,i):\n",
    "    true_positives = confusion_matrix[i][i]\n",
    "    false_negatives = sum(confusion_matrix[i]) - true_positives\n",
    "    return true_positives/(true_positives+false_negatives)\n",
    "\n",
    "print(\"The sensitivity is \")\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    a = sensitivity(matrix,i)\n",
    "    print(a)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 20, we similarly calculate the specificities of each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specificity is \n",
      "0.9997185209416616\n",
      "0.9999028934165333\n",
      "0.9999217573303602\n",
      "0.9999772854857499\n",
      "0.9999736211392654\n",
      "0.7265482304822267\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 20\n",
    "\n",
    "#for i in range(6):\n",
    "def specificity(confusion_matrix,i):\n",
    "    a=np.array(confusion_matrix)\n",
    "    cols = (np.sum(a, axis=0))\n",
    "    rows = (np.sum(a, axis=1))\n",
    "    true_positives = confusion_matrix[i][i]\n",
    "    true_negatives = sum(sum(confusion_matrix)) - rows[i] - cols[i] + confusion_matrix[i][i]\n",
    "    false_positives = cols[i] - true_positives\n",
    "    return true_negatives/(true_negatives+false_positives)\n",
    "\n",
    "print(\"The specificity is \")\n",
    "    \n",
    "for i in range(6):\n",
    "    print(specificity(matrix,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Code Chunks 21 to 28. In the previous part, we notice that TCP and UDP are getting misclassified to a great extent. So, as a check, we are carrying out binary classification between them to see if they can be distinguished in this scenario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 21\n",
    "\n",
    "tcp_udp = df[df['Type'].str.contains(\"udp|tcp\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seeml\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 22\n",
    "\n",
    "tcp_udp['Type'] = tcp_udp['Type'].map({'tcp':0, 'udp':1})\n",
    "tcp_udp_dataset = tcp_udp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>279743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    type\n",
       "Type         \n",
       "0      279743\n",
       "1      316447"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 23\n",
    "\n",
    "pd.crosstab(tcp_udp.Type,columns='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 24\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_tcpudp = scaler.fit_transform(tcp_udp.iloc[:,0:115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 25\n",
    "\n",
    "Y_tcpudp = tcp_udp_dataset[:,115]\n",
    "\n",
    "Xtcpudp_train, Xtcpudp_test, ytcpudp_train, ytcpudp_test =train_test_split(X_tcpudp,Y_tcpudp, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "447142/447142 [==============================] - 5s 10us/step - loss: 7.4778 - acc: 0.5309\n",
      "Epoch 2/5\n",
      "447142/447142 [==============================] - 4s 9us/step - loss: 7.4778 - acc: 0.5309\n",
      "Epoch 3/5\n",
      "447142/447142 [==============================] - 4s 9us/step - loss: 7.4778 - acc: 0.5309\n",
      "Epoch 4/5\n",
      "447142/447142 [==============================] - 4s 9us/step - loss: 7.4778 - acc: 0.5309\n",
      "Epoch 5/5\n",
      "447142/447142 [==============================] - 5s 11us/step - loss: 7.4778 - acc: 0.5309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1700903add8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 26\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=115, activation='softmax'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(Xtcpudp_train, ytcpudp_train, epochs=5, batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Residual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>79037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>70011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  Residual\n",
       "row_0          \n",
       "0.0       79037\n",
       "1.0       70011"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 27\n",
    "\n",
    "predictions = model.predict(Xtcpudp_test)\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "pd.crosstab(rounded-ytcpudp_test,columns=\"Residual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   Type\n",
       "row_0       \n",
       "0      70011\n",
       "1      79037"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 28\n",
    "\n",
    "pd.crosstab(ytcpudp_test,columns=\"Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunks 29 to 31, we extract the data corresponding to TCP and UDP, and perform the Kruskal-Wallis Test on them to test the hypothesis that they are generated from the same distribution. We use a small subset of the data here, to obtain the results within a reasonable computation time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 29\n",
    "\n",
    "df_udp = df[df['Type'].str.contains(\"udp\")]\n",
    "df_tcp = df[df['Type'].str.contains(\"tcp\")]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "dataset_tcp = scaler.fit_transform(df_tcp.iloc[:,0:115])\n",
    "dataset_udp = scaler.fit_transform(df_udp.iloc[:,0:115])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 30\n",
    "\n",
    "X1_tcp, X11_tcp =train_test_split(dataset_tcp, test_size = 0.001)\n",
    "X1_udp, X11_udp =train_test_split(dataset_udp, test_size = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 31\n",
    "\n",
    "pvalue = []\n",
    "\n",
    "for i in range(len(X11_tcp)):\n",
    "    for j in range(len(X11_udp)):\n",
    "        a = (stats.kruskal(dataset_tcp[i], dataset_udp[j]))\n",
    "        pvalue.append(a.pvalue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunk 32, we carry out Bonferroni correction on the list of p values obtained from the Kruskal-Wallis Test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02924740874267688\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 32\n",
    "\n",
    "q = 0\n",
    "alpha = 0.05\n",
    "n = len(X11_tcp) * len(X11_udp)\n",
    "\n",
    "for i in range(len(pvalue)):\n",
    "    if pvalue[i] < (alpha/n):\n",
    "        q = q + 1\n",
    "#print percentage of pvalue that being rejected(not the same distribution)         \n",
    "print(q/len(pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of the hypothesis test, we decide to combine udp and tcp together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunks 33 to 46, we combine the TCP and UDP data into a common class, and carry out the same analysis as before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : In Code Chunk 41, we obtain the accuracy values after every 5 epochs. This is done to get an idea of how the precision of the model increases with increasing number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 33\n",
    "\n",
    "df1 = df\n",
    "df1['Type'] = df.Type.replace([\"tcp\",\"udp\"],\"tcp&udp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 34\n",
    "\n",
    "dataset1 = df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 35\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaled_1 = scaler.fit_transform(df1.iloc[:,0:115])\n",
    "Y_1 = dataset1[:,115]\n",
    "Z_1 = dataset1[:,116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>benign</th>\n",
       "      <td>290051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combo</th>\n",
       "      <td>229551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>junk</th>\n",
       "      <td>116034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scan</th>\n",
       "      <td>110129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcp&amp;udp</th>\n",
       "      <td>596190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      type\n",
       "Type           \n",
       "benign   290051\n",
       "combo    229551\n",
       "junk     116034\n",
       "scan     110129\n",
       "tcp&udp  596190"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 36\n",
    "\n",
    "pd.crosstab(df1.Type,columns='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 37\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_1)\n",
    "encoded_Y = encoder.transform(Y_1)\n",
    "dummy_y1 = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 38\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test,z1_train,z1_test =train_test_split(X_scaled_1,dummy_y1, Z_1, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 39\n",
    "\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(250, input_dim=115, activation='relu'))\n",
    "model2.add(Dense(250, activation='relu'))\n",
    "model2.add(Dense(25, activation='sigmoid'))\n",
    "model2.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 40\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0630 - acc: 0.9735\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0112 - acc: 0.9972\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0060 - acc: 0.9981\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0048 - acc: 0.9983\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0034 - acc: 0.9988\n",
      "1006466/1006466 [==============================] - 26s 26us/step\n",
      "335489/335489 [==============================] - 9s 26us/step\n",
      "epoch : 5\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0026 - acc: 0.9992\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0017 - acc: 0.9995\n",
      "1006466/1006466 [==============================] - 25s 25us/step\n",
      "335489/335489 [==============================] - 9s 25us/step\n",
      "epoch : 10\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0014 - acc: 0.9995\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0018 - acc: 0.9994\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0015 - acc: 0.9995\n",
      "1006466/1006466 [==============================] - 27s 27us/step\n",
      "335489/335489 [==============================] - 9s 26us/step\n",
      "epoch : 15\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 9.9578e-04 - acc: 0.9997\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.0016 - acc: 0.9995\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 9.8068e-04 - acc: 0.9997\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0015 - acc: 0.9995\n",
      "1006466/1006466 [==============================] - 25s 25us/step\n",
      "335489/335489 [==============================] - 8s 24us/step\n",
      "epoch : 20\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 8.9166e-04 - acc: 0.9997\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0017 - acc: 0.9995\n",
      "1006466/1006466 [==============================] - 26s 26us/step\n",
      "335489/335489 [==============================] - 9s 26us/step\n",
      "epoch : 25\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 14s 13us/step - loss: 8.4324e-04 - acc: 0.9997\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 9.9830e-04 - acc: 0.9997- loss: 0.0010 -\n",
      "1006466/1006466 [==============================] - 26s 26us/step\n",
      "335489/335489 [==============================] - 9s 26us/step\n",
      "epoch : 30\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 6.8834e-04 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 9.3327e-04 - acc: 0.9997\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 6.9054e-04 - acc: 0.9998\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0019 - acc: 0.9994\n",
      "1006466/1006466 [==============================] - 25s 25us/step\n",
      "335489/335489 [==============================] - 8s 25us/step\n",
      "epoch : 35\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0010 - acc: 0.9997\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 7.1371e-04 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 8.8597e-04 - acc: 0.9997\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0013 - acc: 0.9996\n",
      "1006466/1006466 [==============================] - 25s 25us/step\n",
      "335489/335489 [==============================] - 8s 25us/step\n",
      "epoch : 40\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.0010 - acc: 0.9997\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 5.8847e-04 - acc: 0.9998\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.0012 - acc: 0.9997\n",
      "1006466/1006466 [==============================] - 25s 25us/step\n",
      "335489/335489 [==============================] - 9s 26us/step\n",
      "epoch : 45\n",
      "Epoch 1/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 9.6896e-04 - acc: 0.9997\n",
      "Epoch 2/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 6.0201e-04 - acc: 0.9998\n",
      "Epoch 3/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 4/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 4.9300e-04 - acc: 0.9999\n",
      "Epoch 5/5\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.0012 - acc: 0.9997\n",
      "1006466/1006466 [==============================] - 25s 25us/step\n",
      "335489/335489 [==============================] - 8s 24us/step\n",
      "[[5, 10, 15, 20, 25, 30, 35, 40, 45, 50], [0.9989174009510056, 0.9996902033784146, 0.9996919918439511, 0.9995570643260988, 0.999738093513662, 0.9997754520112188, 0.9998561302207937, 0.9998312908057484, 0.9998614955795012, 0.9998297011186162], [0.9989400555294973, 0.9996798705188251, 0.9996792743945601, 0.9995654107655264, 0.9997156390492437, 0.9997508116430114, 0.9998414254990091, 0.9998253295753258, 0.9998485792801385, 0.9998366563513864]]\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 41\n",
    "\n",
    "epochs=list()\n",
    "trainacc=list()\n",
    "testacc=list()\n",
    "deltaepochs=5\n",
    "eon=0\n",
    "for i in range(0,10) :\n",
    "        print(\"epoch : \" + str(eon))\n",
    "        model2.fit(X1_train, y1_train, epochs=deltaepochs, batch_size=1500)\n",
    "        scores = model2.evaluate(X1_train, y1_train)\n",
    "        testscores = model2.evaluate(X1_test, y1_test)\n",
    "        eon+=deltaepochs\n",
    "        epochs.append(eon)\n",
    "        trainacc.append(scores[1])\n",
    "        testacc.append(testscores[1])\n",
    "results=[epochs,\n",
    "        trainacc,\n",
    "        testacc]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8660966e-09, 3.6776058e-08, 1.2188056e-07, 9.9999893e-01,\n",
       "        9.1701094e-07],\n",
       "       [1.5989679e-05, 2.9152309e-07, 6.1226025e-08, 2.5130524e-07,\n",
       "        9.9998343e-01],\n",
       "       [1.5989679e-05, 2.9152309e-07, 6.1226025e-08, 2.5130524e-07,\n",
       "        9.9998343e-01],\n",
       "       ...,\n",
       "       [1.5989679e-05, 2.9152309e-07, 6.1226025e-08, 2.5130524e-07,\n",
       "        9.9998343e-01],\n",
       "       [1.3943638e-07, 2.5928302e-05, 9.9997091e-01, 1.3064137e-06,\n",
       "        1.6678731e-06],\n",
       "       [1.0818582e-08, 1.3886477e-04, 9.9986112e-01, 3.8549857e-08,\n",
       "        6.3070780e-09]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 42\n",
    "\n",
    "predictions = model2.predict(X1_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 43\n",
    "\n",
    "prediction = predictions\n",
    "for i in range(len(prediction)):\n",
    "    a = 0\n",
    "    indexpred = 0\n",
    "    for j in range(5):\n",
    "        if prediction[i][j] > a:\n",
    "            a = prediction[i][j]\n",
    "            indexpred = j\n",
    "            \n",
    "    for k in range(5):\n",
    "        if k==indexpred:\n",
    "            prediction[i][k] = 1\n",
    "        else:\n",
    "            prediction[i][k] = 0\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 44\n",
    "\n",
    "index_pred = np.where(np.in1d(prediction, [1]))[0]\n",
    "index_pred = index_pred%5\n",
    "index =  np.where(np.in1d(y1_test, [1]))[0]\n",
    "index = index%5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 72577,     13,      0,      0,     18],\n",
       "       [     2,  57535,     39,      8,      0],\n",
       "       [     1,     35,  28975,      1,      0],\n",
       "       [     3,      8,      0,  27322,      1],\n",
       "       [    17,      6,      0,      0, 148928]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 45\n",
    "\n",
    "matrix = confusion_matrix(index,index_pred)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999125079408554\n",
      "0.9997769021788021\n",
      "0.9998727473839799\n",
      "0.9999707939186449\n",
      "0.9998981440778822\n",
      "0.9995730498016747\n",
      "0.999149069185885\n",
      "0.9987246656555908\n",
      "0.9995609863174069\n",
      "0.9998455868037139\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 46\n",
    "\n",
    "for i in range(5):\n",
    "    print(specificity(matrix,i))\n",
    "    \n",
    "for i in range(5):\n",
    "    print(sensitivity(matrix,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From the confusion matrix and the values for sensitivity and specificity, we observe that the model has done an extremely good job of predicting the types of traffic in the network. <br/>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Code Chunks 47 to 57, we are performing the same analysis as before, but on a slightly different training data set. This time, we have removed the observations corresponding to the 'Scan' attack from the training data. However, the test data set remains the same as before. Thus, we hope to get an idea about our model's predictive power, when it hasn't encountered a particular form of traffic beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : In cell 53, we have used a particular technique of identifying the unknown class in our test data. Briefly, it involves comparing the prediction values (which are basically the probability of that observation belonging to that particular class) to a threshold set by the user (0.5, for us). If all the predictions lie below 0.5, we claim that the prediction is an outlier, and thus corresponds to the unknown class we are trying to identify. <br/>\n",
    "This technique has been explained in more detail (and referenced) in the main report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 47\n",
    "\n",
    "scan_index = np.where(y1_train[:,3] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 48\n",
    "\n",
    "X2_train = np.delete(X1_train,scan_index,axis=0)\n",
    "y2_train = np.delete(np.delete(y1_train,scan_index,axis=0),np.s_[3],1)\n",
    "X2_test = X1_test\n",
    "y2_test = y1_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 49\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(250, input_dim=115, activation='relu'))\n",
    "model3.add(Dense(250, activation='relu'))\n",
    "model3.add(Dense(25, activation='sigmoid'))\n",
    "model3.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 50\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "923671/923671 [==============================] - 11s 12us/step - loss: 0.0775 - acc: 0.9632\n",
      "Epoch 2/50\n",
      "923671/923671 [==============================] - 11s 12us/step - loss: 0.0186 - acc: 0.9954\n",
      "Epoch 3/50\n",
      "923671/923671 [==============================] - 12s 12us/step - loss: 0.0072 - acc: 0.9978\n",
      "Epoch 4/50\n",
      "923671/923671 [==============================] - 11s 12us/step - loss: 0.0056 - acc: 0.9980\n",
      "Epoch 5/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0041 - acc: 0.9987\n",
      "Epoch 6/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0035 - acc: 0.9988\n",
      "Epoch 7/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 8/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0025 - acc: 0.9991\n",
      "Epoch 9/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 10/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 11/50\n",
      "923671/923671 [==============================] - 13s 14us/step - loss: 0.0127 - acc: 0.9965\n",
      "Epoch 12/50\n",
      "923671/923671 [==============================] - 13s 14us/step - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 13/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0025 - acc: 0.9992\n",
      "Epoch 14/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0020 - acc: 0.9994 0s - loss: 0.002\n",
      "Epoch 15/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0024 - acc: 0.9992\n",
      "Epoch 16/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0015 - acc: 0.9995\n",
      "Epoch 17/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 18/50\n",
      "923671/923671 [==============================] - 12s 12us/step - loss: 0.0016 - acc: 0.9995\n",
      "Epoch 19/50\n",
      "923671/923671 [==============================] - 11s 12us/step - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 20/50\n",
      "923671/923671 [==============================] - 11s 12us/step - loss: 0.0010 - acc: 0.9997\n",
      "Epoch 21/50\n",
      "923671/923671 [==============================] - 11s 12us/step - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 22/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0016 - acc: 0.9995\n",
      "Epoch 23/50\n",
      "923671/923671 [==============================] - 13s 14us/step - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 24/50\n",
      "923671/923671 [==============================] - 13s 14us/step - loss: 0.0016 - acc: 0.9995\n",
      "Epoch 25/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 26/50\n",
      "923671/923671 [==============================] - 13s 14us/step - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 27/50\n",
      "923671/923671 [==============================] - 12s 14us/step - loss: 0.0016 - acc: 0.9994\n",
      "Epoch 28/50\n",
      "923671/923671 [==============================] - 13s 14us/step - loss: 7.9362e-04 - acc: 0.9997\n",
      "Epoch 29/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0041 - acc: 0.9991\n",
      "Epoch 30/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 31/50\n",
      "923671/923671 [==============================] - 13s 14us/step - loss: 9.0237e-04 - acc: 0.9998\n",
      "Epoch 32/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0016 - acc: 0.9995\n",
      "Epoch 33/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 34/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 35/50\n",
      "923671/923671 [==============================] - 12s 14us/step - loss: 7.7699e-04 - acc: 0.9998\n",
      "Epoch 36/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 37/50\n",
      "923671/923671 [==============================] - 12s 14us/step - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 38/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 9.6342e-04 - acc: 0.9997\n",
      "Epoch 39/50\n",
      "923671/923671 [==============================] - 12s 14us/step - loss: 0.0015 - acc: 0.9996 0s - loss: 0.00\n",
      "Epoch 40/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0023 - acc: 0.9994\n",
      "Epoch 41/50\n",
      "923671/923671 [==============================] - 12s 12us/step - loss: 9.8619e-04 - acc: 0.9997\n",
      "Epoch 42/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 7.2420e-04 - acc: 0.9998\n",
      "Epoch 43/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0019 - acc: 0.9994\n",
      "Epoch 44/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 45/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 46/50\n",
      "923671/923671 [==============================] - 13s 14us/step - loss: 9.0527e-04 - acc: 0.9997\n",
      "Epoch 47/50\n",
      "923671/923671 [==============================] - 14s 15us/step - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 48/50\n",
      "923671/923671 [==============================] - 14s 15us/step - loss: 7.4263e-04 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "923671/923671 [==============================] - 13s 14us/step - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 50/50\n",
      "923671/923671 [==============================] - 12s 13us/step - loss: 8.9025e-04 - acc: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16fcb62b278>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 51\n",
    "\n",
    "model3.fit(X2_train, y2_train, epochs=50, batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 52\n",
    "\n",
    "predictions = model3.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 53\n",
    "\n",
    "prediction1 = predictions\n",
    "threshold = 0.5\n",
    "\n",
    "for i in range(len(prediction1)):\n",
    "    for j in range(4):\n",
    "        if prediction1[i][j] >= threshold:\n",
    "            prediction1[i][j] = 1\n",
    "        else:\n",
    "            prediction1[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 54\n",
    "\n",
    "prediction2 = np.insert(prediction1,3,0,axis=1)\n",
    "for i in range(len(prediction2)):\n",
    "    if sum(prediction2[i]) == 0:\n",
    "        prediction2[i][3] = 1\n",
    "prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 55\n",
    "\n",
    "index_pred = np.where(np.in1d(prediction2, [1]))[0]\n",
    "index_pred = index_pred%5\n",
    "index= np.where(np.in1d(y2_test, [1]))[0]\n",
    "index = index%5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 72595,      0,      0,      1,     12],\n",
       "       [    10,  57523,     50,      1,      0],\n",
       "       [    13,    433,  28564,      2,      0],\n",
       "       [  6399,   1682,      0,    944,  18309],\n",
       "       [    17,      2,      0,      1, 148931]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 56\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix3 = confusion_matrix(index,index_pred)\n",
    "matrix3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity is \n",
      "0.9998209563684443\n",
      "0.9989406779661016\n",
      "0.9845581138839101\n",
      "0.03453574303065779\n",
      "0.9998657276554035\n",
      "The specificity is \n",
      "0.9755060274420746\n",
      "0.9923822889116785\n",
      "0.999836855620487\n",
      "0.9999837743992471\n",
      "0.9017840868884625\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 57\n",
    "\n",
    "print(\"The sensitivity is \")   \n",
    "for i in range(5):\n",
    "    print(sensitivity(matrix3,i))\n",
    "print(\"The specificity is \") \n",
    "for i in range(5):\n",
    "    print(specificity(matrix3,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the model **does not** do a very good job in classifying 'Scan' if it hasn't seen it before. However, we note that majority of the observations corresponding to 'Scan' (around 76%) are being misclassified as 'TCP UDP', with the next highest proportion going to benign, and some to Junk and Combo respectively. <br/>\n",
    "We have discussed the implications of this in more detail in the report. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the previous section, the prediction of 'Scan' wasn't very successful. In order to check if this was a one-off for the model, or if it misclassified every unseen attack, we decided to carry out the same analysis, but with the 'Combo' attack hidden from the training data set. As before, the test data set remains the same. <br/>\n",
    "This analysis is provided in Code Chunks 58 to 66."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 58\n",
    "\n",
    "combo_index = np.where(y1_train[:,1] == 1)\n",
    "X2_train = np.delete(X1_train,combo_index,axis=0)\n",
    "y2_train = np.delete(np.delete(y1_train,combo_index,axis=0),np.s_[1],1)\n",
    "X2_test = X1_test\n",
    "y2_test = y1_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 59\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(250, input_dim=115, activation='relu'))\n",
    "model3.add(Dense(250, activation='relu'))\n",
    "model3.add(Dense(25, activation='sigmoid'))\n",
    "model3.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 60\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 0.0276 - acc: 0.9945\n",
      "Epoch 2/50\n",
      "834499/834499 [==============================] - 9s 11us/step - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 3/50\n",
      "834499/834499 [==============================] - 9s 11us/step - loss: 0.0018 - acc: 0.9997\n",
      "Epoch 4/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 5/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 8.9014e-04 - acc: 0.9998\n",
      "Epoch 6/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 6.9997e-04 - acc: 0.9999\n",
      "Epoch 7/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 5.3657e-04 - acc: 0.9999 1s - loss:\n",
      "Epoch 8/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 4.5387e-04 - acc: 0.9999\n",
      "Epoch 9/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 4.7600e-04 - acc: 0.9999\n",
      "Epoch 10/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 3.8035e-04 - acc: 0.9999\n",
      "Epoch 11/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 3.8936e-04 - acc: 0.9999\n",
      "Epoch 12/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 3.3770e-04 - acc: 0.9999\n",
      "Epoch 13/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 3.8368e-04 - acc: 0.9999\n",
      "Epoch 14/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.6575e-04 - acc: 0.9999\n",
      "Epoch 15/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.6444e-04 - acc: 0.9999\n",
      "Epoch 16/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 3.2925e-04 - acc: 0.9999\n",
      "Epoch 17/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 4.6462e-04 - acc: 0.9999\n",
      "Epoch 18/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 3.6445e-04 - acc: 0.9999\n",
      "Epoch 19/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 2.7641e-04 - acc: 0.9999\n",
      "Epoch 20/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.4052e-04 - acc: 0.9999\n",
      "Epoch 21/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.3132e-04 - acc: 0.9999\n",
      "Epoch 22/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 3.0185e-04 - acc: 0.9999\n",
      "Epoch 23/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.4111e-04 - acc: 0.9999\n",
      "Epoch 24/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.4879e-04 - acc: 0.9999\n",
      "Epoch 25/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 4.3757e-04 - acc: 0.9999\n",
      "Epoch 26/50\n",
      "834499/834499 [==============================] - 11s 14us/step - loss: 3.9487e-04 - acc: 0.9999\n",
      "Epoch 27/50\n",
      "834499/834499 [==============================] - 11s 14us/step - loss: 2.3667e-04 - acc: 0.9999\n",
      "Epoch 28/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.4330e-04 - acc: 0.9999\n",
      "Epoch 29/50\n",
      "834499/834499 [==============================] - 11s 14us/step - loss: 2.1348e-04 - acc: 0.9999\n",
      "Epoch 30/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 1.9834e-04 - acc: 0.9999\n",
      "Epoch 31/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.2298e-04 - acc: 0.9999\n",
      "Epoch 32/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.1039e-04 - acc: 0.9999\n",
      "Epoch 33/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 1.9444e-04 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 3.5694e-04 - acc: 0.9999\n",
      "Epoch 35/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.2919e-04 - acc: 0.9999\n",
      "Epoch 36/50\n",
      "834499/834499 [==============================] - 11s 14us/step - loss: 2.1418e-04 - acc: 0.9999\n",
      "Epoch 37/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 8.1928e-04 - acc: 0.9994\n",
      "Epoch 38/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 3.6950e-04 - acc: 0.9999\n",
      "Epoch 39/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 2.6799e-04 - acc: 0.9999\n",
      "Epoch 40/50\n",
      "834499/834499 [==============================] - 10s 13us/step - loss: 2.5494e-04 - acc: 0.9999\n",
      "Epoch 41/50\n",
      "834499/834499 [==============================] - 10s 13us/step - loss: 2.1997e-04 - acc: 0.9999 1s - loss: 1\n",
      "Epoch 42/50\n",
      "834499/834499 [==============================] - 10s 13us/step - loss: 2.4738e-04 - acc: 0.9999\n",
      "Epoch 43/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 2.3293e-04 - acc: 0.9999 0s - loss: 2.3892e-04 - \n",
      "Epoch 44/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 2.1620e-04 - acc: 0.9999\n",
      "Epoch 45/50\n",
      "834499/834499 [==============================] - 10s 13us/step - loss: 3.3273e-04 - acc: 0.9999\n",
      "Epoch 46/50\n",
      "834499/834499 [==============================] - 10s 12us/step - loss: 2.5764e-04 - acc: 0.9999\n",
      "Epoch 47/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.5428e-04 - acc: 0.9999\n",
      "Epoch 48/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.1413e-04 - acc: 0.9999\n",
      "Epoch 49/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.4570e-04 - acc: 0.9999\n",
      "Epoch 50/50\n",
      "834499/834499 [==============================] - 11s 13us/step - loss: 2.5802e-04 - acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x172b9322668>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 61\n",
    "\n",
    "model3.fit(X2_train, y2_train, epochs=50, batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5003640e-06, 8.0471573e-06, 9.9998808e-01, 2.3266318e-06],\n",
       "       [1.2395269e-05, 1.6900100e-06, 7.8988108e-08, 9.9998581e-01],\n",
       "       [1.2395269e-05, 1.6900100e-06, 7.8988108e-08, 9.9998581e-01],\n",
       "       ...,\n",
       "       [1.2395269e-05, 1.6900100e-06, 7.8988108e-08, 9.9998581e-01],\n",
       "       [5.2193059e-07, 9.9999559e-01, 3.1246148e-06, 8.7264328e-07],\n",
       "       [2.7143778e-07, 9.9999595e-01, 1.6527050e-06, 2.1866613e-06]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 62\n",
    "\n",
    "predictions = model3.predict(X2_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 63\n",
    "\n",
    "prediction1 = predictions\n",
    "threshold = 0.5\n",
    "\n",
    "for i in range(len(prediction1)):\n",
    "    for j in range(4):\n",
    "        if prediction1[i][j] >= threshold:\n",
    "            prediction1[i][j] = 1\n",
    "        else:\n",
    "            prediction1[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 64\n",
    "\n",
    "prediction2 = np.insert(prediction1,1,0,axis=1)\n",
    "for i in range(len(prediction2)):\n",
    "    if sum(prediction2[i]) == 0:\n",
    "        prediction2[i][1] = 1\n",
    "prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE cHUNK 65\n",
    "\n",
    "index_pred = np.where(np.in1d(prediction2, [1]))[0]\n",
    "index_pred = index_pred%5\n",
    "index= np.where(np.in1d(y2_test, [1]))[0]\n",
    "index = index%5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 72595      0      0      1     12]\n",
      " [     5      0  57577      1      1]\n",
      " [     6      0  29006      0      0]\n",
      " [     5      3      0  27326      0]\n",
      " [     7      2      0      0 148942]]\n",
      "0.9998209563684443\n",
      "0.0\n",
      "0.999793189025231\n",
      "0.9997073242116046\n",
      "0.9999395774449316\n",
      "0.9999125079408554\n",
      "0.999982008240226\n",
      "0.8121327212156214\n",
      "0.9999935097596988\n",
      "0.9999303091059194\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 66\n",
    "\n",
    "matrix = confusion_matrix(index,index_pred)\n",
    "print(matrix)\n",
    "\n",
    "for i in range(5):\n",
    "    print(sensitivity(matrix,i))\n",
    "    \n",
    "for i in range(5):\n",
    "    print(specificity(matrix,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the classification in this case is worse than 'Scan'. More than 99% of the 'Combo' observations are being misclassified as 'Junk' traffic. An extremely low proportion is classified as 'benign' (less than 0.01%). <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the third variant of our model, we are considering the same training and test data as before. Here, we will be removing all the observations corresponding to a particular device. Then we will be attempting to classify the test data on the basis of the device labels, and check the performance of our model. <br/>\n",
    "In the beginning however, we are running a normal neural network model (similar to our first model) to try and predict the device labels, after learning on the **entire** training data. <br/>\n",
    "This analysis is provided in Code Chunks 67 to 76. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 67\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Z_1)\n",
    "encoded_Z = encoder.transform(Z_1)\n",
    "dummy_z1 = np_utils.to_categorical(encoded_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 68\n",
    "\n",
    "X3_train, X3_test,z3_train,z3_test =train_test_split(X_scaled_1,dummy_z1, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 69\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(250, input_dim=115, activation='relu'))\n",
    "model4.add(Dense(250, activation='relu'))\n",
    "model4.add(Dense(25, activation='sigmoid'))\n",
    "model4.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 70\n",
    "\n",
    "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1006466/1006466 [==============================] - 12s 11us/step - loss: 0.4176 - acc: 0.8010\n",
      "Epoch 2/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.4050 - acc: 0.8037\n",
      "Epoch 3/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.4039 - acc: 0.8038\n",
      "Epoch 4/50\n",
      "1006466/1006466 [==============================] - 11s 11us/step - loss: 0.4032 - acc: 0.8038\n",
      "Epoch 5/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4028 - acc: 0.8039\n",
      "Epoch 6/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4025 - acc: 0.8039\n",
      "Epoch 7/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.4022 - acc: 0.8039\n",
      "Epoch 8/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.4019 - acc: 0.8040\n",
      "Epoch 9/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4016 - acc: 0.8040\n",
      "Epoch 10/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4015 - acc: 0.8040\n",
      "Epoch 11/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.4012 - acc: 0.8041\n",
      "Epoch 12/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4012 - acc: 0.8041 1s - \n",
      "Epoch 13/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4010 - acc: 0.8041\n",
      "Epoch 14/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4009 - acc: 0.8041\n",
      "Epoch 15/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4009 - acc: 0.8042\n",
      "Epoch 16/50\n",
      "1006466/1006466 [==============================] - 14s 13us/step - loss: 0.4007 - acc: 0.8042\n",
      "Epoch 17/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4006 - acc: 0.8042\n",
      "Epoch 18/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.4006 - acc: 0.8042\n",
      "Epoch 19/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.4005 - acc: 0.8042\n",
      "Epoch 20/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.4007 - acc: 0.8041\n",
      "Epoch 21/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4008 - acc: 0.8041\n",
      "Epoch 22/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4004 - acc: 0.8042\n",
      "Epoch 23/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.4003 - acc: 0.8042\n",
      "Epoch 24/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.4004 - acc: 0.8042\n",
      "Epoch 25/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.4004 - acc: 0.8042\n",
      "Epoch 26/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4003 - acc: 0.8042\n",
      "Epoch 27/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4002 - acc: 0.8043\n",
      "Epoch 28/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.4002 - acc: 0.8042\n",
      "Epoch 29/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.4001 - acc: 0.8042\n",
      "Epoch 30/50\n",
      "1006466/1006466 [==============================] - 14s 14us/step - loss: 0.4001 - acc: 0.8043\n",
      "Epoch 31/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4002 - acc: 0.8042\n",
      "Epoch 32/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4001 - acc: 0.8043\n",
      "Epoch 33/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4000 - acc: 0.8043\n",
      "Epoch 34/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4000 - acc: 0.8042\n",
      "Epoch 35/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4001 - acc: 0.8043\n",
      "Epoch 36/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4000 - acc: 0.8042\n",
      "Epoch 37/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.4000 - acc: 0.8043\n",
      "Epoch 38/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.4000 - acc: 0.8043\n",
      "Epoch 39/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.3999 - acc: 0.8043\n",
      "Epoch 40/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.3999 - acc: 0.8043\n",
      "Epoch 41/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.3999 - acc: 0.8043\n",
      "Epoch 42/50\n",
      "1006466/1006466 [==============================] - 13s 12us/step - loss: 0.3999 - acc: 0.8043\n",
      "Epoch 43/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.3999 - acc: 0.8043\n",
      "Epoch 44/50\n",
      "1006466/1006466 [==============================] - 12s 12us/step - loss: 0.3999 - acc: 0.8043\n",
      "Epoch 45/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.4000 - acc: 0.8043\n",
      "Epoch 46/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.3999 - acc: 0.8043\n",
      "Epoch 47/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.3998 - acc: 0.8043\n",
      "Epoch 48/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.3998 - acc: 0.8043\n",
      "Epoch 49/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.3998 - acc: 0.8043\n",
      "Epoch 50/50\n",
      "1006466/1006466 [==============================] - 13s 13us/step - loss: 0.3998 - acc: 0.8042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x172f4a59080>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 71\n",
    "\n",
    "model4.fit(X3_train, z3_train, epochs=50, batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.2808965e-01, 3.3462146e-01, 3.3728662e-01, 2.2440001e-06],\n",
       "       [3.2808965e-01, 3.3462146e-01, 3.3728662e-01, 2.2440001e-06],\n",
       "       [1.2789493e-04, 4.5839854e-04, 9.9834740e-01, 1.0664049e-03],\n",
       "       ...,\n",
       "       [2.4626538e-01, 2.5308105e-01, 2.4878961e-01, 2.5186402e-01],\n",
       "       [3.2808965e-01, 3.3462146e-01, 3.3728662e-01, 2.2440001e-06],\n",
       "       [2.8175911e-01, 2.5617385e-01, 2.6322564e-01, 1.9884133e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 72\n",
    "\n",
    "predictions = model4.predict(X3_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 73\n",
    "\n",
    "prediction = predictions\n",
    "for i in range(len(prediction)):\n",
    "    a = 0\n",
    "    indexpred = 0\n",
    "    for j in range(4):\n",
    "        if prediction[i][j] > a:\n",
    "            a = prediction[i][j]\n",
    "            indexpred = j\n",
    "            \n",
    "    for k in range(4):\n",
    "        if k==indexpred:\n",
    "            prediction[i][k] = 1\n",
    "        else:\n",
    "            prediction[i][k] = 0\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 74\n",
    "\n",
    "index_pred = np.where(np.in1d(prediction, [1]))[0]\n",
    "index_pred = index_pred%4\n",
    "index =  np.where(np.in1d(z3_test, [1]))[0]\n",
    "index = index%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18021,  5801, 62847,  4603],\n",
       "       [ 4577, 49861, 63408,  4238],\n",
       "       [ 4831,  4947, 67117,  4433],\n",
       "       [ 4014,  5621, 13851, 17319]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 75\n",
    "\n",
    "matrix4 = confusion_matrix(index,index_pred)\n",
    "matrix4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity is \n",
      "0.19744280830922956\n",
      "0.4084155171848891\n",
      "0.8252631320086563\n",
      "0.4244332802352653\n",
      "The specificity is \n",
      "0.9450406810336709\n",
      "0.9232960802230501\n",
      "0.44875098854662987\n",
      "0.9549551383855248\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 76\n",
    "\n",
    "print(\"The sensitivity is \")   \n",
    "for i in range(4):\n",
    "    print(sensitivity(matrix4,i))\n",
    "print(\"The specificity is \") \n",
    "for i in range(4):\n",
    "    print(specificity(matrix4,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrixc, we observe that the model does not do a very good job of classifying the observations according to their device labels. <br/>\n",
    "From the sensitivity values, we see that the highest value is 0.77 (corresponding to Baby Monitor). This means that for that device, only 77% of the observations were correctly classfied, and the model performed even more poorly for the other devices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are removing all the observations corresponding to the 'doorbell' device from the training data set and attempting to predict device labels based on the same test data set. <br/>\n",
    "This analysis is provided in Code Chunks 77 to 81."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 77\n",
    "\n",
    "doorbell_index = np.where(z3_train[:,0] == 1)\n",
    "X4_train = np.delete(X3_train,doorbell_index,axis=0)\n",
    "z4_train = np.delete(np.delete(z3_train,doorbell_index,axis=0),np.s_[0],1)\n",
    "X4_test = X3_test\n",
    "z4_test = z3_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE CHUNK 78\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(250, input_dim=115, activation='relu'))\n",
    "model5.add(Dense(250, activation='relu'))\n",
    "model5.add(Dense(25, activation='sigmoid'))\n",
    "model5.add(Dense(3, activation='softmax'))\n",
    "model5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4324 - acc: 0.7442\n",
      "Epoch 2/50\n",
      "731540/731540 [==============================] - 9s 13us/step - loss: 0.4124 - acc: 0.7482\n",
      "Epoch 3/50\n",
      "731540/731540 [==============================] - 9s 13us/step - loss: 0.4106 - acc: 0.7487\n",
      "Epoch 4/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4098 - acc: 0.7493\n",
      "Epoch 5/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4090 - acc: 0.7492\n",
      "Epoch 6/50\n",
      "731540/731540 [==============================] - 9s 13us/step - loss: 0.4084 - acc: 0.7492\n",
      "Epoch 7/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4078 - acc: 0.7492\n",
      "Epoch 8/50\n",
      "731540/731540 [==============================] - 9s 13us/step - loss: 0.4070 - acc: 0.7499\n",
      "Epoch 9/50\n",
      "731540/731540 [==============================] - 9s 13us/step - loss: 0.4068 - acc: 0.7501\n",
      "Epoch 10/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4066 - acc: 0.7495\n",
      "Epoch 11/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4061 - acc: 0.7500\n",
      "Epoch 12/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4063 - acc: 0.7495\n",
      "Epoch 13/50\n",
      "731540/731540 [==============================] - 9s 13us/step - loss: 0.4057 - acc: 0.7501\n",
      "Epoch 14/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4056 - acc: 0.7500\n",
      "Epoch 15/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4056 - acc: 0.7499\n",
      "Epoch 16/50\n",
      "731540/731540 [==============================] - 9s 13us/step - loss: 0.4054 - acc: 0.7503\n",
      "Epoch 17/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4054 - acc: 0.7504\n",
      "Epoch 18/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4062 - acc: 0.7494\n",
      "Epoch 19/50\n",
      "731540/731540 [==============================] - 11s 15us/step - loss: 0.4053 - acc: 0.7496\n",
      "Epoch 20/50\n",
      "731540/731540 [==============================] - 10s 14us/step - loss: 0.4053 - acc: 0.7499\n",
      "Epoch 21/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4051 - acc: 0.7502\n",
      "Epoch 22/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4051 - acc: 0.7503\n",
      "Epoch 23/50\n",
      "731540/731540 [==============================] - 9s 13us/step - loss: 0.4051 - acc: 0.7503\n",
      "Epoch 24/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4052 - acc: 0.7505\n",
      "Epoch 25/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4049 - acc: 0.7503\n",
      "Epoch 26/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4051 - acc: 0.7506\n",
      "Epoch 27/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4059 - acc: 0.7499\n",
      "Epoch 28/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4051 - acc: 0.7505\n",
      "Epoch 29/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4054 - acc: 0.7499\n",
      "Epoch 30/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4050 - acc: 0.7501\n",
      "Epoch 31/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4047 - acc: 0.7504\n",
      "Epoch 32/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4047 - acc: 0.7501\n",
      "Epoch 33/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4049 - acc: 0.7503\n",
      "Epoch 34/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4050 - acc: 0.7497\n",
      "Epoch 35/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4046 - acc: 0.7501\n",
      "Epoch 36/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4045 - acc: 0.7504\n",
      "Epoch 37/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4046 - acc: 0.7505\n",
      "Epoch 38/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4045 - acc: 0.7503\n",
      "Epoch 39/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4047 - acc: 0.7504\n",
      "Epoch 40/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4044 - acc: 0.7507\n",
      "Epoch 41/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4045 - acc: 0.7504\n",
      "Epoch 42/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4046 - acc: 0.7507\n",
      "Epoch 43/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4047 - acc: 0.7502\n",
      "Epoch 44/50\n",
      "731540/731540 [==============================] - 9s 12us/step - loss: 0.4046 - acc: 0.7502\n",
      "Epoch 45/50\n",
      "731540/731540 [==============================] - 9s 13us/step - loss: 0.4046 - acc: 0.7501\n",
      "Epoch 46/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4044 - acc: 0.7502\n",
      "Epoch 47/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4045 - acc: 0.7498\n",
      "Epoch 48/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4044 - acc: 0.7501\n",
      "Epoch 49/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4044 - acc: 0.7503\n",
      "Epoch 50/50\n",
      "731540/731540 [==============================] - 10s 13us/step - loss: 0.4044 - acc: 0.7505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x172f4bd42b0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE CHUNK 79\n",
    "\n",
    "model5.fit(X4_train, z4_train, epochs=50, batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26654 12315 40485  4067]\n",
      " [27126 12293 40696  4141]\n",
      " [26999 12107 40653  4103]\n",
      " [26684 12514 40488  4164]]\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 80\n",
    "\n",
    "predictions = model5.predict(X4_test)\n",
    "prediction1 = predictions\n",
    "threshold = 0.5\n",
    "for i in range(len(prediction1)):\n",
    "    for j in range(3):\n",
    "        if prediction1[i][j] >= threshold:\n",
    "            prediction1[i][j] = 1\n",
    "        else:\n",
    "            prediction1[i][j] = 0\n",
    "prediction2 = np.insert(prediction1,0,0,axis=1)\n",
    "for i in range(len(prediction2)):\n",
    "    if sum(prediction2[i]) == 0:\n",
    "        prediction2[i][0] = 1\n",
    "index_pred = np.where(np.in1d(prediction2, [1]))[0]\n",
    "index_pred = index_pred%4\n",
    "index= np.where(np.in1d(y1_test, [1]))[0]\n",
    "index = index%4\n",
    "#confusionmatrix\n",
    "matrix5 = confusion_matrix(index,index_pred)\n",
    "print(matrix5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sensitivity is \n",
      "0.3191293207696268\n",
      "0.14590058868211167\n",
      "0.4847606782571367\n",
      "0.04966010733452594\n",
      "The specificity is \n",
      "0.6792886398272796\n",
      "0.8529810972284692\n",
      "0.5164708079816553\n",
      "0.9510767408867465\n"
     ]
    }
   ],
   "source": [
    "#CODE CHUNK 81\n",
    "\n",
    "print(\"The sensitivity is \")   \n",
    "for i in range(4):\n",
    "    print(sensitivity(matrix5,i))\n",
    "print(\"The specificity is \") \n",
    "for i in range(4):\n",
    "    print(specificity(matrix5,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous analysis, we see that the model does not do a very good job of predicting the unknown device from the test data set. The percentage of correctly classified observations for each class range from 29% to 65%, which is not very good for a system designed to detect malicious traffic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : A more detailed discussion of the results obtained from each of the models is provided in the main report. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
